2023-02-24 01:39:36,224:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-24 01:39:36,224:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-24 01:39:36,224:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-24 01:39:36,224:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-24 01:39:51,019:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-24 01:41:48,310:INFO:PyCaret RegressionExperiment
2023-02-24 01:41:48,310:INFO:Logging name: reg-default-name
2023-02-24 01:41:48,311:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-24 01:41:48,311:INFO:version 3.0.0.rc9
2023-02-24 01:41:48,311:INFO:Initializing setup()
2023-02-24 01:41:48,311:INFO:self.USI: 5a7f
2023-02-24 01:41:48,311:INFO:self._variable_keys: {'memory', 'fold_generator', 'target_param', 'y', 'exp_id', 'fold_shuffle_param', 'pipeline', 'data', 'log_plots_param', 'exp_name_log', 'X', 'gpu_n_jobs_param', 'fold_groups_param', 'idx', 'transform_target_param', '_available_plots', 'seed', 'logging_param', 'n_jobs_param', 'USI', 'html_param', 'X_train', 'gpu_param', '_ml_usecase', 'y_test', 'y_train', 'X_test'}
2023-02-24 01:41:48,311:INFO:Checking environment
2023-02-24 01:41:48,311:INFO:python_version: 3.10.8
2023-02-24 01:41:48,311:INFO:python_build: ('main', 'Oct 13 2022 10:17:43')
2023-02-24 01:41:48,311:INFO:machine: x86_64
2023-02-24 01:41:48,354:INFO:platform: macOS-12.6.1-x86_64-i386-64bit
2023-02-24 01:41:48,359:INFO:Memory: svmem(total=8589934592, available=3112882176, percent=63.8, used=4505161728, free=76316672, active=3038547968, inactive=2940518400, wired=1466613760)
2023-02-24 01:41:48,359:INFO:Physical Core: 2
2023-02-24 01:41:48,360:INFO:Logical Core: 2
2023-02-24 01:41:48,360:INFO:Checking libraries
2023-02-24 01:41:48,360:INFO:System:
2023-02-24 01:41:48,360:INFO:    python: 3.10.8 (main, Oct 13 2022, 10:17:43) [Clang 14.0.0 (clang-1400.0.29.102)]
2023-02-24 01:41:48,360:INFO:executable: /usr/local/opt/python@3.10/bin/python3.10
2023-02-24 01:41:48,360:INFO:   machine: macOS-12.6.1-x86_64-i386-64bit
2023-02-24 01:41:48,360:INFO:PyCaret required dependencies:
2023-02-24 01:41:48,361:INFO:                 pip: 23.0.1
2023-02-24 01:41:48,361:INFO:          setuptools: 65.4.1
2023-02-24 01:41:48,361:INFO:             pycaret: 3.0.0rc9
2023-02-24 01:41:48,362:INFO:             IPython: 8.10.0
2023-02-24 01:41:48,362:INFO:          ipywidgets: 8.0.4
2023-02-24 01:41:48,362:INFO:                tqdm: 4.64.1
2023-02-24 01:41:48,362:INFO:               numpy: 1.23.5
2023-02-24 01:41:48,362:INFO:              pandas: 1.5.2
2023-02-24 01:41:48,362:INFO:              jinja2: 3.1.2
2023-02-24 01:41:48,362:INFO:               scipy: 1.9.3
2023-02-24 01:41:48,362:INFO:              joblib: 1.2.0
2023-02-24 01:41:48,362:INFO:             sklearn: 1.0.2
2023-02-24 01:41:48,362:INFO:                pyod: 1.0.7
2023-02-24 01:41:48,362:INFO:            imblearn: 0.10.1
2023-02-24 01:41:48,362:INFO:   category_encoders: 2.6.0
2023-02-24 01:41:48,362:INFO:            lightgbm: 3.3.5
2023-02-24 01:41:48,362:INFO:               numba: 0.56.4
2023-02-24 01:41:48,362:INFO:            requests: 2.28.2
2023-02-24 01:41:48,362:INFO:          matplotlib: 3.6.3
2023-02-24 01:41:48,362:INFO:          scikitplot: 0.3.7
2023-02-24 01:41:48,362:INFO:         yellowbrick: 1.5
2023-02-24 01:41:48,362:INFO:              plotly: 5.13.0
2023-02-24 01:41:48,363:INFO:             kaleido: 0.2.1
2023-02-24 01:41:48,363:INFO:         statsmodels: 0.13.5
2023-02-24 01:41:48,363:INFO:              sktime: 0.16.1
2023-02-24 01:41:48,363:INFO:               tbats: 1.1.2
2023-02-24 01:41:48,363:INFO:            pmdarima: 2.0.2
2023-02-24 01:41:48,363:INFO:              psutil: 5.9.4
2023-02-24 01:41:48,363:INFO:PyCaret optional dependencies:
2023-02-24 01:41:48,370:INFO:                shap: Not installed
2023-02-24 01:41:48,370:INFO:           interpret: Not installed
2023-02-24 01:41:48,370:INFO:                umap: Not installed
2023-02-24 01:41:48,370:INFO:    pandas_profiling: 4.0.0
2023-02-24 01:41:48,371:INFO:  explainerdashboard: Not installed
2023-02-24 01:41:48,371:INFO:             autoviz: Not installed
2023-02-24 01:41:48,371:INFO:           fairlearn: Not installed
2023-02-24 01:41:48,371:INFO:             xgboost: Not installed
2023-02-24 01:41:48,371:INFO:            catboost: Not installed
2023-02-24 01:41:48,371:INFO:              kmodes: Not installed
2023-02-24 01:41:48,371:INFO:             mlxtend: Not installed
2023-02-24 01:41:48,372:INFO:       statsforecast: Not installed
2023-02-24 01:41:48,372:INFO:        tune_sklearn: Not installed
2023-02-24 01:41:48,372:INFO:                 ray: Not installed
2023-02-24 01:41:48,372:INFO:            hyperopt: Not installed
2023-02-24 01:41:48,372:INFO:              optuna: Not installed
2023-02-24 01:41:48,372:INFO:               skopt: Not installed
2023-02-24 01:41:48,372:INFO:              mlflow: Not installed
2023-02-24 01:41:48,372:INFO:              gradio: Not installed
2023-02-24 01:41:48,372:INFO:             fastapi: Not installed
2023-02-24 01:41:48,372:INFO:             uvicorn: Not installed
2023-02-24 01:41:48,372:INFO:              m2cgen: Not installed
2023-02-24 01:41:48,372:INFO:           evidently: Not installed
2023-02-24 01:41:48,372:INFO:               fugue: Not installed
2023-02-24 01:41:48,372:INFO:           streamlit: 1.17.0
2023-02-24 01:41:48,372:INFO:             prophet: Not installed
2023-02-24 01:41:48,373:INFO:None
2023-02-24 01:41:48,373:INFO:Set up data.
2023-02-24 01:41:48,401:INFO:Set up train/test split.
2023-02-24 01:41:48,416:INFO:Set up index.
2023-02-24 01:41:48,416:INFO:Set up folding strategy.
2023-02-24 01:41:48,416:INFO:Assigning column types.
2023-02-24 01:41:48,427:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-24 01:41:48,428:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-24 01:41:48,437:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-24 01:41:48,446:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-24 01:41:48,548:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-24 01:41:48,626:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-24 01:41:48,628:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:33,967:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-24 01:44:33,968:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-24 01:44:33,968:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-24 01:44:33,968:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-24 01:44:34,745:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-24 01:44:47,476:INFO:PyCaret RegressionExperiment
2023-02-24 01:44:47,477:INFO:Logging name: reg-default-name
2023-02-24 01:44:47,477:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-24 01:44:47,477:INFO:version 3.0.0.rc9
2023-02-24 01:44:47,477:INFO:Initializing setup()
2023-02-24 01:44:47,477:INFO:self.USI: f27a
2023-02-24 01:44:47,477:INFO:self._variable_keys: {'y_test', '_available_plots', 'y', 'exp_name_log', 'y_train', 'log_plots_param', 'exp_id', 'idx', 'X_test', 'seed', 'n_jobs_param', 'gpu_n_jobs_param', 'target_param', 'html_param', 'fold_groups_param', 'X_train', 'transform_target_param', 'logging_param', 'data', 'fold_generator', 'USI', 'X', 'memory', 'fold_shuffle_param', '_ml_usecase', 'pipeline', 'gpu_param'}
2023-02-24 01:44:47,478:INFO:Checking environment
2023-02-24 01:44:47,478:INFO:python_version: 3.10.8
2023-02-24 01:44:47,478:INFO:python_build: ('main', 'Oct 13 2022 10:17:43')
2023-02-24 01:44:47,478:INFO:machine: x86_64
2023-02-24 01:44:47,522:INFO:platform: macOS-12.6.1-x86_64-i386-64bit
2023-02-24 01:44:47,532:INFO:Memory: svmem(total=8589934592, available=3087400960, percent=64.1, used=4537487360, free=23638016, active=3065573376, inactive=3004375040, wired=1471913984)
2023-02-24 01:44:47,532:INFO:Physical Core: 2
2023-02-24 01:44:47,533:INFO:Logical Core: 2
2023-02-24 01:44:47,533:INFO:Checking libraries
2023-02-24 01:44:47,533:INFO:System:
2023-02-24 01:44:47,533:INFO:    python: 3.10.8 (main, Oct 13 2022, 10:17:43) [Clang 14.0.0 (clang-1400.0.29.102)]
2023-02-24 01:44:47,533:INFO:executable: /usr/local/opt/python@3.10/bin/python3.10
2023-02-24 01:44:47,533:INFO:   machine: macOS-12.6.1-x86_64-i386-64bit
2023-02-24 01:44:47,534:INFO:PyCaret required dependencies:
2023-02-24 01:44:47,540:INFO:                 pip: 23.0.1
2023-02-24 01:44:47,540:INFO:          setuptools: 65.4.1
2023-02-24 01:44:47,540:INFO:             pycaret: 3.0.0rc9
2023-02-24 01:44:47,540:INFO:             IPython: 8.10.0
2023-02-24 01:44:47,540:INFO:          ipywidgets: 8.0.4
2023-02-24 01:44:47,540:INFO:                tqdm: 4.64.1
2023-02-24 01:44:47,540:INFO:               numpy: 1.23.5
2023-02-24 01:44:47,541:INFO:              pandas: 1.5.2
2023-02-24 01:44:47,541:INFO:              jinja2: 3.1.2
2023-02-24 01:44:47,541:INFO:               scipy: 1.9.3
2023-02-24 01:44:47,541:INFO:              joblib: 1.2.0
2023-02-24 01:44:47,541:INFO:             sklearn: 1.0.2
2023-02-24 01:44:47,541:INFO:                pyod: 1.0.7
2023-02-24 01:44:47,541:INFO:            imblearn: 0.10.1
2023-02-24 01:44:47,541:INFO:   category_encoders: 2.6.0
2023-02-24 01:44:47,541:INFO:            lightgbm: 3.3.5
2023-02-24 01:44:47,541:INFO:               numba: 0.56.4
2023-02-24 01:44:47,541:INFO:            requests: 2.28.2
2023-02-24 01:44:47,541:INFO:          matplotlib: 3.6.3
2023-02-24 01:44:47,541:INFO:          scikitplot: 0.3.7
2023-02-24 01:44:47,541:INFO:         yellowbrick: 1.5
2023-02-24 01:44:47,541:INFO:              plotly: 5.13.0
2023-02-24 01:44:47,541:INFO:             kaleido: 0.2.1
2023-02-24 01:44:47,541:INFO:         statsmodels: 0.13.5
2023-02-24 01:44:47,541:INFO:              sktime: 0.16.1
2023-02-24 01:44:47,542:INFO:               tbats: 1.1.2
2023-02-24 01:44:47,542:INFO:            pmdarima: 2.0.2
2023-02-24 01:44:47,542:INFO:              psutil: 5.9.4
2023-02-24 01:44:47,542:INFO:PyCaret optional dependencies:
2023-02-24 01:44:47,551:INFO:                shap: Not installed
2023-02-24 01:44:47,551:INFO:           interpret: Not installed
2023-02-24 01:44:47,551:INFO:                umap: Not installed
2023-02-24 01:44:47,551:INFO:    pandas_profiling: 4.0.0
2023-02-24 01:44:47,551:INFO:  explainerdashboard: Not installed
2023-02-24 01:44:47,552:INFO:             autoviz: Not installed
2023-02-24 01:44:47,552:INFO:           fairlearn: Not installed
2023-02-24 01:44:47,552:INFO:             xgboost: Not installed
2023-02-24 01:44:47,552:INFO:            catboost: Not installed
2023-02-24 01:44:47,553:INFO:              kmodes: Not installed
2023-02-24 01:44:47,553:INFO:             mlxtend: Not installed
2023-02-24 01:44:47,553:INFO:       statsforecast: Not installed
2023-02-24 01:44:47,553:INFO:        tune_sklearn: Not installed
2023-02-24 01:44:47,553:INFO:                 ray: Not installed
2023-02-24 01:44:47,553:INFO:            hyperopt: Not installed
2023-02-24 01:44:47,553:INFO:              optuna: Not installed
2023-02-24 01:44:47,553:INFO:               skopt: Not installed
2023-02-24 01:44:47,553:INFO:              mlflow: Not installed
2023-02-24 01:44:47,554:INFO:              gradio: Not installed
2023-02-24 01:44:47,554:INFO:             fastapi: Not installed
2023-02-24 01:44:47,554:INFO:             uvicorn: Not installed
2023-02-24 01:44:47,554:INFO:              m2cgen: Not installed
2023-02-24 01:44:47,554:INFO:           evidently: Not installed
2023-02-24 01:44:47,554:INFO:               fugue: Not installed
2023-02-24 01:44:47,554:INFO:           streamlit: 1.17.0
2023-02-24 01:44:47,554:INFO:             prophet: Not installed
2023-02-24 01:44:47,554:INFO:None
2023-02-24 01:44:47,555:INFO:Set up data.
2023-02-24 01:44:47,572:INFO:Set up train/test split.
2023-02-24 01:44:47,580:INFO:Set up index.
2023-02-24 01:44:47,581:INFO:Set up folding strategy.
2023-02-24 01:44:47,581:INFO:Assigning column types.
2023-02-24 01:44:47,587:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-24 01:44:47,587:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-24 01:44:47,594:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-24 01:44:47,601:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-24 01:44:47,698:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-24 01:44:47,767:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-24 01:44:47,769:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:48,884:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:48,885:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-24 01:44:48,892:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-24 01:44:48,898:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-24 01:44:48,985:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-24 01:44:49,051:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-24 01:44:49,052:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:49,052:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:49,053:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-24 01:44:49,059:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-24 01:44:49,066:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-24 01:44:49,154:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-24 01:44:49,220:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-24 01:44:49,221:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:49,221:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:49,229:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-24 01:44:49,235:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-24 01:44:49,321:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-24 01:44:49,389:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-24 01:44:49,389:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:49,389:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:49,390:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-24 01:44:49,403:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-24 01:44:49,489:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-24 01:44:49,556:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-24 01:44:49,557:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:49,557:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:49,571:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-24 01:44:49,657:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-24 01:44:49,724:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-24 01:44:49,725:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:49,725:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:49,726:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-24 01:44:49,823:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-24 01:44:49,893:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-24 01:44:49,894:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:49,894:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:49,991:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-24 01:44:50,056:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-24 01:44:50,057:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:50,057:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:50,058:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-24 01:44:50,164:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-24 01:44:50,231:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:50,231:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:50,331:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-24 01:44:50,398:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:50,398:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:50,399:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-24 01:44:50,564:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:50,564:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:50,730:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:50,730:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:50,733:INFO:Preparing preprocessing pipeline...
2023-02-24 01:44:50,734:INFO:Set up simple imputation.
2023-02-24 01:44:50,777:INFO:Finished creating preprocessing pipeline.
2023-02-24 01:44:50,786:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/dq/s9918lj122qb5j_dx_8x106m0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'cp', 'trestbps',
                                             'chol', 'fbs', 'restecg',
                                             'thalach', 'exang', 'oldpeak',
                                             'slope', 'ca', 'thal'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-02-24 01:44:50,786:INFO:Creating final display dataframe.
2023-02-24 01:44:50,932:INFO:Setup _display_container:                     Description             Value
0                    Session id              7646
1                        Target            target
2                   Target type        Regression
3           Original data shape         (303, 14)
4        Transformed data shape         (303, 14)
5   Transformed train set shape         (212, 14)
6    Transformed test set shape          (91, 14)
7              Numeric features                13
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              f27a
2023-02-24 01:44:51,117:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:51,118:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:51,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:51,284:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:44:51,285:INFO:setup() successfully completed in 3.81s...............
2023-02-24 01:44:51,325:INFO:Initializing compare_models()
2023-02-24 01:44:51,326:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x1305e6e60>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x1305e6e60>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-24 01:44:51,326:INFO:Checking exceptions
2023-02-24 01:44:51,329:INFO:Preparing display monitor
2023-02-24 01:44:51,364:INFO:Initializing Linear Regression
2023-02-24 01:44:51,366:INFO:Total runtime is 2.5331974029541016e-05 minutes
2023-02-24 01:44:51,374:INFO:SubProcess create_model() called ==================================
2023-02-24 01:44:51,376:INFO:Initializing create_model()
2023-02-24 01:44:51,376:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1305e6e60>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1309a5660>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:44:51,377:INFO:Checking exceptions
2023-02-24 01:44:51,377:INFO:Importing libraries
2023-02-24 01:44:51,377:INFO:Copying training dataset
2023-02-24 01:44:51,389:INFO:Defining folds
2023-02-24 01:44:51,390:INFO:Declaring metric variables
2023-02-24 01:44:51,390:INFO:Importing untrained model
2023-02-24 01:44:51,391:INFO:Linear Regression Imported successfully
2023-02-24 01:44:51,394:INFO:Starting cross validation
2023-02-24 01:44:51,411:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:06,013:INFO:Calculating mean and std
2023-02-24 01:45:06,017:INFO:Creating metrics dataframe
2023-02-24 01:45:06,029:INFO:Uploading results into container
2023-02-24 01:45:06,032:INFO:Uploading model into container now
2023-02-24 01:45:06,033:INFO:_master_model_container: 1
2023-02-24 01:45:06,033:INFO:_display_container: 2
2023-02-24 01:45:06,034:INFO:LinearRegression(n_jobs=-1)
2023-02-24 01:45:06,034:INFO:create_model() successfully completed......................................
2023-02-24 01:45:06,235:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:06,235:INFO:Creating metrics dataframe
2023-02-24 01:45:06,245:INFO:Initializing Lasso Regression
2023-02-24 01:45:06,245:INFO:Total runtime is 0.24802117745081584 minutes
2023-02-24 01:45:06,246:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:06,246:INFO:Initializing create_model()
2023-02-24 01:45:06,247:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1305e6e60>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1309a5660>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:06,247:INFO:Checking exceptions
2023-02-24 01:45:06,248:INFO:Importing libraries
2023-02-24 01:45:06,248:INFO:Copying training dataset
2023-02-24 01:45:06,258:INFO:Defining folds
2023-02-24 01:45:06,258:INFO:Declaring metric variables
2023-02-24 01:45:06,259:INFO:Importing untrained model
2023-02-24 01:45:06,260:INFO:Lasso Regression Imported successfully
2023-02-24 01:45:06,261:INFO:Starting cross validation
2023-02-24 01:45:06,262:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:06,803:INFO:Calculating mean and std
2023-02-24 01:45:06,803:INFO:Creating metrics dataframe
2023-02-24 01:45:06,812:INFO:Uploading results into container
2023-02-24 01:45:06,813:INFO:Uploading model into container now
2023-02-24 01:45:06,813:INFO:_master_model_container: 2
2023-02-24 01:45:06,814:INFO:_display_container: 2
2023-02-24 01:45:06,814:INFO:Lasso(random_state=7646)
2023-02-24 01:45:06,814:INFO:create_model() successfully completed......................................
2023-02-24 01:45:06,940:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:06,940:INFO:Creating metrics dataframe
2023-02-24 01:45:06,947:INFO:Initializing Ridge Regression
2023-02-24 01:45:06,948:INFO:Total runtime is 0.25972568194071455 minutes
2023-02-24 01:45:06,948:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:06,948:INFO:Initializing create_model()
2023-02-24 01:45:06,948:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1305e6e60>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1309a5660>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:06,948:INFO:Checking exceptions
2023-02-24 01:45:06,948:INFO:Importing libraries
2023-02-24 01:45:06,949:INFO:Copying training dataset
2023-02-24 01:45:06,955:INFO:Defining folds
2023-02-24 01:45:06,955:INFO:Declaring metric variables
2023-02-24 01:45:06,956:INFO:Importing untrained model
2023-02-24 01:45:06,956:INFO:Ridge Regression Imported successfully
2023-02-24 01:45:06,957:INFO:Starting cross validation
2023-02-24 01:45:06,958:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:07,341:INFO:Calculating mean and std
2023-02-24 01:45:07,342:INFO:Creating metrics dataframe
2023-02-24 01:45:07,351:INFO:Uploading results into container
2023-02-24 01:45:07,352:INFO:Uploading model into container now
2023-02-24 01:45:07,352:INFO:_master_model_container: 3
2023-02-24 01:45:07,352:INFO:_display_container: 2
2023-02-24 01:45:07,353:INFO:Ridge(random_state=7646)
2023-02-24 01:45:07,353:INFO:create_model() successfully completed......................................
2023-02-24 01:45:07,505:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:07,505:INFO:Creating metrics dataframe
2023-02-24 01:45:07,512:INFO:Initializing Elastic Net
2023-02-24 01:45:07,512:INFO:Total runtime is 0.26913028160731 minutes
2023-02-24 01:45:07,512:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:07,512:INFO:Initializing create_model()
2023-02-24 01:45:07,512:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1305e6e60>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1309a5660>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:07,513:INFO:Checking exceptions
2023-02-24 01:45:07,513:INFO:Importing libraries
2023-02-24 01:45:07,513:INFO:Copying training dataset
2023-02-24 01:45:07,518:INFO:Defining folds
2023-02-24 01:45:07,519:INFO:Declaring metric variables
2023-02-24 01:45:07,519:INFO:Importing untrained model
2023-02-24 01:45:07,520:INFO:Elastic Net Imported successfully
2023-02-24 01:45:07,520:INFO:Starting cross validation
2023-02-24 01:45:07,522:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:07,857:INFO:Calculating mean and std
2023-02-24 01:45:07,860:INFO:Creating metrics dataframe
2023-02-24 01:45:07,865:INFO:Uploading results into container
2023-02-24 01:45:07,866:INFO:Uploading model into container now
2023-02-24 01:45:07,867:INFO:_master_model_container: 4
2023-02-24 01:45:07,867:INFO:_display_container: 2
2023-02-24 01:45:07,867:INFO:ElasticNet(random_state=7646)
2023-02-24 01:45:07,867:INFO:create_model() successfully completed......................................
2023-02-24 01:45:08,009:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:08,009:INFO:Creating metrics dataframe
2023-02-24 01:45:08,020:INFO:Initializing Least Angle Regression
2023-02-24 01:45:08,020:INFO:Total runtime is 0.27760269641876223 minutes
2023-02-24 01:45:08,021:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:08,021:INFO:Initializing create_model()
2023-02-24 01:45:08,021:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1305e6e60>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1309a5660>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:08,021:INFO:Checking exceptions
2023-02-24 01:45:08,021:INFO:Importing libraries
2023-02-24 01:45:08,021:INFO:Copying training dataset
2023-02-24 01:45:08,047:INFO:Defining folds
2023-02-24 01:45:08,047:INFO:Declaring metric variables
2023-02-24 01:45:08,048:INFO:Importing untrained model
2023-02-24 01:45:08,048:INFO:Least Angle Regression Imported successfully
2023-02-24 01:45:08,049:INFO:Starting cross validation
2023-02-24 01:45:08,050:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:08,161:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:08,171:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:08,214:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:08,226:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:08,321:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:08,325:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:08,327:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:08,373:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:08,429:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:08,430:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:08,462:INFO:Calculating mean and std
2023-02-24 01:45:08,463:INFO:Creating metrics dataframe
2023-02-24 01:45:08,468:INFO:Uploading results into container
2023-02-24 01:45:08,470:INFO:Uploading model into container now
2023-02-24 01:45:08,471:INFO:_master_model_container: 5
2023-02-24 01:45:08,471:INFO:_display_container: 2
2023-02-24 01:45:08,473:INFO:Lars(random_state=7646)
2023-02-24 01:45:08,473:INFO:create_model() successfully completed......................................
2023-02-24 01:45:08,640:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:08,640:INFO:Creating metrics dataframe
2023-02-24 01:45:08,651:INFO:Initializing Lasso Least Angle Regression
2023-02-24 01:45:08,651:INFO:Total runtime is 0.288118584950765 minutes
2023-02-24 01:45:08,651:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:08,652:INFO:Initializing create_model()
2023-02-24 01:45:08,653:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1305e6e60>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1309a5660>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:08,653:INFO:Checking exceptions
2023-02-24 01:45:08,653:INFO:Importing libraries
2023-02-24 01:45:08,653:INFO:Copying training dataset
2023-02-24 01:45:08,665:INFO:Defining folds
2023-02-24 01:45:08,665:INFO:Declaring metric variables
2023-02-24 01:45:08,666:INFO:Importing untrained model
2023-02-24 01:45:08,667:INFO:Lasso Least Angle Regression Imported successfully
2023-02-24 01:45:08,667:INFO:Starting cross validation
2023-02-24 01:45:08,668:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:08,767:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-24 01:45:08,778:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-24 01:45:08,829:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-24 01:45:08,844:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-24 01:45:08,917:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-24 01:45:08,922:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-24 01:45:08,970:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-24 01:45:08,979:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-24 01:45:09,048:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-24 01:45:09,050:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-24 01:45:09,089:INFO:Calculating mean and std
2023-02-24 01:45:09,092:INFO:Creating metrics dataframe
2023-02-24 01:45:09,099:INFO:Uploading results into container
2023-02-24 01:45:09,100:INFO:Uploading model into container now
2023-02-24 01:45:09,100:INFO:_master_model_container: 6
2023-02-24 01:45:09,100:INFO:_display_container: 2
2023-02-24 01:45:09,101:INFO:LassoLars(random_state=7646)
2023-02-24 01:45:09,101:INFO:create_model() successfully completed......................................
2023-02-24 01:45:09,253:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:09,253:INFO:Creating metrics dataframe
2023-02-24 01:45:09,262:INFO:Initializing Orthogonal Matching Pursuit
2023-02-24 01:45:09,262:INFO:Total runtime is 0.2982967972755432 minutes
2023-02-24 01:45:09,262:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:09,262:INFO:Initializing create_model()
2023-02-24 01:45:09,263:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1305e6e60>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1309a5660>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:09,263:INFO:Checking exceptions
2023-02-24 01:45:09,263:INFO:Importing libraries
2023-02-24 01:45:09,263:INFO:Copying training dataset
2023-02-24 01:45:09,271:INFO:Defining folds
2023-02-24 01:45:09,271:INFO:Declaring metric variables
2023-02-24 01:45:09,272:INFO:Importing untrained model
2023-02-24 01:45:09,272:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-24 01:45:09,272:INFO:Starting cross validation
2023-02-24 01:45:09,274:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:09,327:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:09,361:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:09,382:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:09,424:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:09,460:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:09,556:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:09,573:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:09,621:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:09,638:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:09,698:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:09,727:INFO:Calculating mean and std
2023-02-24 01:45:09,728:INFO:Creating metrics dataframe
2023-02-24 01:45:09,734:INFO:Uploading results into container
2023-02-24 01:45:09,735:INFO:Uploading model into container now
2023-02-24 01:45:09,738:INFO:_master_model_container: 7
2023-02-24 01:45:09,738:INFO:_display_container: 2
2023-02-24 01:45:09,738:INFO:OrthogonalMatchingPursuit()
2023-02-24 01:45:09,738:INFO:create_model() successfully completed......................................
2023-02-24 01:45:09,899:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:09,899:INFO:Creating metrics dataframe
2023-02-24 01:45:09,912:INFO:Initializing Bayesian Ridge
2023-02-24 01:45:09,912:INFO:Total runtime is 0.3091381311416626 minutes
2023-02-24 01:45:09,913:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:09,913:INFO:Initializing create_model()
2023-02-24 01:45:09,913:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1305e6e60>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1309a5660>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:09,913:INFO:Checking exceptions
2023-02-24 01:45:09,913:INFO:Importing libraries
2023-02-24 01:45:09,913:INFO:Copying training dataset
2023-02-24 01:45:09,926:INFO:Defining folds
2023-02-24 01:45:09,926:INFO:Declaring metric variables
2023-02-24 01:45:09,927:INFO:Importing untrained model
2023-02-24 01:45:09,928:INFO:Bayesian Ridge Imported successfully
2023-02-24 01:45:09,929:INFO:Starting cross validation
2023-02-24 01:45:09,930:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:10,379:INFO:Calculating mean and std
2023-02-24 01:45:10,380:INFO:Creating metrics dataframe
2023-02-24 01:45:10,389:INFO:Uploading results into container
2023-02-24 01:45:10,390:INFO:Uploading model into container now
2023-02-24 01:45:10,391:INFO:_master_model_container: 8
2023-02-24 01:45:10,392:INFO:_display_container: 2
2023-02-24 01:45:10,392:INFO:BayesianRidge()
2023-02-24 01:45:10,392:INFO:create_model() successfully completed......................................
2023-02-24 01:45:10,537:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:10,537:INFO:Creating metrics dataframe
2023-02-24 01:45:10,547:INFO:Initializing Passive Aggressive Regressor
2023-02-24 01:45:10,547:INFO:Total runtime is 0.3197139342625936 minutes
2023-02-24 01:45:10,547:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:10,548:INFO:Initializing create_model()
2023-02-24 01:45:10,548:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1305e6e60>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1309a5660>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:10,548:INFO:Checking exceptions
2023-02-24 01:45:10,548:INFO:Importing libraries
2023-02-24 01:45:10,548:INFO:Copying training dataset
2023-02-24 01:45:10,555:INFO:Defining folds
2023-02-24 01:45:10,556:INFO:Declaring metric variables
2023-02-24 01:45:10,556:INFO:Importing untrained model
2023-02-24 01:45:10,557:INFO:Passive Aggressive Regressor Imported successfully
2023-02-24 01:45:10,558:INFO:Starting cross validation
2023-02-24 01:45:10,559:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:10,970:INFO:Calculating mean and std
2023-02-24 01:45:10,971:INFO:Creating metrics dataframe
2023-02-24 01:45:10,979:INFO:Uploading results into container
2023-02-24 01:45:10,980:INFO:Uploading model into container now
2023-02-24 01:45:10,981:INFO:_master_model_container: 9
2023-02-24 01:45:10,981:INFO:_display_container: 2
2023-02-24 01:45:10,981:INFO:PassiveAggressiveRegressor(random_state=7646)
2023-02-24 01:45:10,981:INFO:create_model() successfully completed......................................
2023-02-24 01:45:11,124:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:11,125:INFO:Creating metrics dataframe
2023-02-24 01:45:11,135:INFO:Initializing Huber Regressor
2023-02-24 01:45:11,135:INFO:Total runtime is 0.3295156478881836 minutes
2023-02-24 01:45:11,135:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:11,136:INFO:Initializing create_model()
2023-02-24 01:45:11,136:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1305e6e60>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1309a5660>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:11,136:INFO:Checking exceptions
2023-02-24 01:45:11,136:INFO:Importing libraries
2023-02-24 01:45:11,136:INFO:Copying training dataset
2023-02-24 01:45:11,145:INFO:Defining folds
2023-02-24 01:45:11,145:INFO:Declaring metric variables
2023-02-24 01:45:11,145:INFO:Importing untrained model
2023-02-24 01:45:11,146:INFO:Huber Regressor Imported successfully
2023-02-24 01:45:11,146:INFO:Starting cross validation
2023-02-24 01:45:11,148:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:11,320:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-24 01:45:11,345:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-24 01:45:11,375:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-24 01:45:11,388:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-24 01:45:11,678:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-24 01:45:11,686:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-24 01:45:11,702:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-24 01:45:11,723:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-24 01:45:11,934:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-24 01:45:11,975:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-24 01:45:12,030:INFO:Calculating mean and std
2023-02-24 01:45:12,031:INFO:Creating metrics dataframe
2023-02-24 01:45:12,038:INFO:Uploading results into container
2023-02-24 01:45:12,039:INFO:Uploading model into container now
2023-02-24 01:45:12,039:INFO:_master_model_container: 10
2023-02-24 01:45:12,039:INFO:_display_container: 2
2023-02-24 01:45:12,040:INFO:HuberRegressor()
2023-02-24 01:45:12,040:INFO:create_model() successfully completed......................................
2023-02-24 01:45:12,298:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:12,298:INFO:Creating metrics dataframe
2023-02-24 01:45:12,315:INFO:Initializing K Neighbors Regressor
2023-02-24 01:45:12,315:INFO:Total runtime is 0.3491795341173808 minutes
2023-02-24 01:45:12,315:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:12,316:INFO:Initializing create_model()
2023-02-24 01:45:12,316:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1305e6e60>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1309a5660>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:12,316:INFO:Checking exceptions
2023-02-24 01:45:12,316:INFO:Importing libraries
2023-02-24 01:45:12,316:INFO:Copying training dataset
2023-02-24 01:45:12,334:INFO:Defining folds
2023-02-24 01:45:12,334:INFO:Declaring metric variables
2023-02-24 01:45:12,335:INFO:Importing untrained model
2023-02-24 01:45:12,340:INFO:K Neighbors Regressor Imported successfully
2023-02-24 01:45:12,342:INFO:Starting cross validation
2023-02-24 01:45:12,344:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:12,849:INFO:Calculating mean and std
2023-02-24 01:45:12,850:INFO:Creating metrics dataframe
2023-02-24 01:45:12,857:INFO:Uploading results into container
2023-02-24 01:45:12,858:INFO:Uploading model into container now
2023-02-24 01:45:12,859:INFO:_master_model_container: 11
2023-02-24 01:45:12,859:INFO:_display_container: 2
2023-02-24 01:45:12,860:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-24 01:45:12,860:INFO:create_model() successfully completed......................................
2023-02-24 01:45:12,999:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:12,999:INFO:Creating metrics dataframe
2023-02-24 01:45:13,008:INFO:Initializing Decision Tree Regressor
2023-02-24 01:45:13,009:INFO:Total runtime is 0.3607418775558472 minutes
2023-02-24 01:45:13,009:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:13,011:INFO:Initializing create_model()
2023-02-24 01:45:13,011:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1305e6e60>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1309a5660>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:13,011:INFO:Checking exceptions
2023-02-24 01:45:13,011:INFO:Importing libraries
2023-02-24 01:45:13,011:INFO:Copying training dataset
2023-02-24 01:45:13,018:INFO:Defining folds
2023-02-24 01:45:13,018:INFO:Declaring metric variables
2023-02-24 01:45:13,019:INFO:Importing untrained model
2023-02-24 01:45:13,020:INFO:Decision Tree Regressor Imported successfully
2023-02-24 01:45:13,020:INFO:Starting cross validation
2023-02-24 01:45:13,021:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:13,437:INFO:Calculating mean and std
2023-02-24 01:45:13,438:INFO:Creating metrics dataframe
2023-02-24 01:45:13,445:INFO:Uploading results into container
2023-02-24 01:45:13,446:INFO:Uploading model into container now
2023-02-24 01:45:13,447:INFO:_master_model_container: 12
2023-02-24 01:45:13,447:INFO:_display_container: 2
2023-02-24 01:45:13,447:INFO:DecisionTreeRegressor(random_state=7646)
2023-02-24 01:45:13,448:INFO:create_model() successfully completed......................................
2023-02-24 01:45:13,586:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:13,586:INFO:Creating metrics dataframe
2023-02-24 01:45:13,595:INFO:Initializing Random Forest Regressor
2023-02-24 01:45:13,595:INFO:Total runtime is 0.37051356633504234 minutes
2023-02-24 01:45:13,595:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:13,595:INFO:Initializing create_model()
2023-02-24 01:45:13,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1305e6e60>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1309a5660>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:13,596:INFO:Checking exceptions
2023-02-24 01:45:13,596:INFO:Importing libraries
2023-02-24 01:45:13,596:INFO:Copying training dataset
2023-02-24 01:45:13,601:INFO:Defining folds
2023-02-24 01:45:13,602:INFO:Declaring metric variables
2023-02-24 01:45:13,603:INFO:Importing untrained model
2023-02-24 01:45:13,603:INFO:Random Forest Regressor Imported successfully
2023-02-24 01:45:13,604:INFO:Starting cross validation
2023-02-24 01:45:13,605:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:16,601:INFO:Calculating mean and std
2023-02-24 01:45:16,602:INFO:Creating metrics dataframe
2023-02-24 01:45:16,608:INFO:Uploading results into container
2023-02-24 01:45:16,609:INFO:Uploading model into container now
2023-02-24 01:45:16,609:INFO:_master_model_container: 13
2023-02-24 01:45:16,609:INFO:_display_container: 2
2023-02-24 01:45:16,610:INFO:RandomForestRegressor(n_jobs=-1, random_state=7646)
2023-02-24 01:45:16,610:INFO:create_model() successfully completed......................................
2023-02-24 01:45:16,739:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:16,740:INFO:Creating metrics dataframe
2023-02-24 01:45:16,748:INFO:Initializing Extra Trees Regressor
2023-02-24 01:45:16,748:INFO:Total runtime is 0.4230658292770386 minutes
2023-02-24 01:45:16,748:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:16,749:INFO:Initializing create_model()
2023-02-24 01:45:16,749:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1305e6e60>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1309a5660>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:16,749:INFO:Checking exceptions
2023-02-24 01:45:16,749:INFO:Importing libraries
2023-02-24 01:45:16,749:INFO:Copying training dataset
2023-02-24 01:45:16,756:INFO:Defining folds
2023-02-24 01:45:16,756:INFO:Declaring metric variables
2023-02-24 01:45:16,757:INFO:Importing untrained model
2023-02-24 01:45:16,758:INFO:Extra Trees Regressor Imported successfully
2023-02-24 01:45:16,758:INFO:Starting cross validation
2023-02-24 01:45:16,759:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:19,542:INFO:Calculating mean and std
2023-02-24 01:45:19,543:INFO:Creating metrics dataframe
2023-02-24 01:45:19,549:INFO:Uploading results into container
2023-02-24 01:45:19,550:INFO:Uploading model into container now
2023-02-24 01:45:19,551:INFO:_master_model_container: 14
2023-02-24 01:45:19,551:INFO:_display_container: 2
2023-02-24 01:45:19,551:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=7646)
2023-02-24 01:45:19,551:INFO:create_model() successfully completed......................................
2023-02-24 01:45:19,680:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:19,680:INFO:Creating metrics dataframe
2023-02-24 01:45:19,688:INFO:Initializing AdaBoost Regressor
2023-02-24 01:45:19,688:INFO:Total runtime is 0.4720622817675273 minutes
2023-02-24 01:45:19,688:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:19,688:INFO:Initializing create_model()
2023-02-24 01:45:19,689:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1305e6e60>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1309a5660>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:19,689:INFO:Checking exceptions
2023-02-24 01:45:19,689:INFO:Importing libraries
2023-02-24 01:45:19,689:INFO:Copying training dataset
2023-02-24 01:45:19,694:INFO:Defining folds
2023-02-24 01:45:19,694:INFO:Declaring metric variables
2023-02-24 01:45:19,695:INFO:Importing untrained model
2023-02-24 01:45:19,695:INFO:AdaBoost Regressor Imported successfully
2023-02-24 01:45:19,696:INFO:Starting cross validation
2023-02-24 01:45:19,697:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:21,625:INFO:Calculating mean and std
2023-02-24 01:45:21,626:INFO:Creating metrics dataframe
2023-02-24 01:45:21,632:INFO:Uploading results into container
2023-02-24 01:45:21,634:INFO:Uploading model into container now
2023-02-24 01:45:21,634:INFO:_master_model_container: 15
2023-02-24 01:45:21,634:INFO:_display_container: 2
2023-02-24 01:45:21,635:INFO:AdaBoostRegressor(random_state=7646)
2023-02-24 01:45:21,635:INFO:create_model() successfully completed......................................
2023-02-24 01:45:21,800:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:21,801:INFO:Creating metrics dataframe
2023-02-24 01:45:21,817:INFO:Initializing Gradient Boosting Regressor
2023-02-24 01:45:21,817:INFO:Total runtime is 0.5075440128644307 minutes
2023-02-24 01:45:21,817:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:21,817:INFO:Initializing create_model()
2023-02-24 01:45:21,817:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1305e6e60>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1309a5660>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:21,818:INFO:Checking exceptions
2023-02-24 01:45:21,818:INFO:Importing libraries
2023-02-24 01:45:21,818:INFO:Copying training dataset
2023-02-24 01:45:21,831:INFO:Defining folds
2023-02-24 01:45:21,831:INFO:Declaring metric variables
2023-02-24 01:45:21,832:INFO:Importing untrained model
2023-02-24 01:45:21,832:INFO:Gradient Boosting Regressor Imported successfully
2023-02-24 01:45:21,833:INFO:Starting cross validation
2023-02-24 01:45:21,834:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:24,273:INFO:Calculating mean and std
2023-02-24 01:45:24,274:INFO:Creating metrics dataframe
2023-02-24 01:45:24,279:INFO:Uploading results into container
2023-02-24 01:45:24,280:INFO:Uploading model into container now
2023-02-24 01:45:24,281:INFO:_master_model_container: 16
2023-02-24 01:45:24,281:INFO:_display_container: 2
2023-02-24 01:45:24,281:INFO:GradientBoostingRegressor(random_state=7646)
2023-02-24 01:45:24,281:INFO:create_model() successfully completed......................................
2023-02-24 01:45:24,406:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:24,406:INFO:Creating metrics dataframe
2023-02-24 01:45:24,414:INFO:Initializing Light Gradient Boosting Machine
2023-02-24 01:45:24,414:INFO:Total runtime is 0.5508341789245605 minutes
2023-02-24 01:45:24,414:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:24,415:INFO:Initializing create_model()
2023-02-24 01:45:24,415:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1305e6e60>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1309a5660>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:24,415:INFO:Checking exceptions
2023-02-24 01:45:24,415:INFO:Importing libraries
2023-02-24 01:45:24,415:INFO:Copying training dataset
2023-02-24 01:45:24,421:INFO:Defining folds
2023-02-24 01:45:24,421:INFO:Declaring metric variables
2023-02-24 01:45:24,421:INFO:Importing untrained model
2023-02-24 01:45:24,422:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-24 01:45:24,423:INFO:Starting cross validation
2023-02-24 01:45:24,424:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:25,051:INFO:Calculating mean and std
2023-02-24 01:45:25,051:INFO:Creating metrics dataframe
2023-02-24 01:45:25,061:INFO:Uploading results into container
2023-02-24 01:45:25,062:INFO:Uploading model into container now
2023-02-24 01:45:25,062:INFO:_master_model_container: 17
2023-02-24 01:45:25,062:INFO:_display_container: 2
2023-02-24 01:45:25,063:INFO:LGBMRegressor(random_state=7646)
2023-02-24 01:45:25,063:INFO:create_model() successfully completed......................................
2023-02-24 01:45:25,192:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:25,193:INFO:Creating metrics dataframe
2023-02-24 01:45:25,201:INFO:Initializing Dummy Regressor
2023-02-24 01:45:25,201:INFO:Total runtime is 0.5639532486597697 minutes
2023-02-24 01:45:25,202:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:25,202:INFO:Initializing create_model()
2023-02-24 01:45:25,202:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1305e6e60>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1309a5660>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:25,202:INFO:Checking exceptions
2023-02-24 01:45:25,202:INFO:Importing libraries
2023-02-24 01:45:25,202:INFO:Copying training dataset
2023-02-24 01:45:25,209:INFO:Defining folds
2023-02-24 01:45:25,209:INFO:Declaring metric variables
2023-02-24 01:45:25,210:INFO:Importing untrained model
2023-02-24 01:45:25,210:INFO:Dummy Regressor Imported successfully
2023-02-24 01:45:25,211:INFO:Starting cross validation
2023-02-24 01:45:25,212:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:25,610:INFO:Calculating mean and std
2023-02-24 01:45:25,611:INFO:Creating metrics dataframe
2023-02-24 01:45:25,617:INFO:Uploading results into container
2023-02-24 01:45:25,618:INFO:Uploading model into container now
2023-02-24 01:45:25,619:INFO:_master_model_container: 18
2023-02-24 01:45:25,619:INFO:_display_container: 2
2023-02-24 01:45:25,620:INFO:DummyRegressor()
2023-02-24 01:45:25,620:INFO:create_model() successfully completed......................................
2023-02-24 01:45:25,760:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:25,760:INFO:Creating metrics dataframe
2023-02-24 01:45:25,773:INFO:Initializing create_model()
2023-02-24 01:45:25,773:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x1305e6e60>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:25,773:INFO:Checking exceptions
2023-02-24 01:45:25,776:INFO:Importing libraries
2023-02-24 01:45:25,776:INFO:Copying training dataset
2023-02-24 01:45:25,783:INFO:Defining folds
2023-02-24 01:45:25,783:INFO:Declaring metric variables
2023-02-24 01:45:25,783:INFO:Importing untrained model
2023-02-24 01:45:25,783:INFO:Declaring custom model
2023-02-24 01:45:25,784:INFO:Bayesian Ridge Imported successfully
2023-02-24 01:45:25,785:INFO:Cross validation set to False
2023-02-24 01:45:25,785:INFO:Fitting Model
2023-02-24 01:45:25,814:INFO:BayesianRidge()
2023-02-24 01:45:25,815:INFO:create_model() successfully completed......................................
2023-02-24 01:45:25,986:INFO:_master_model_container: 18
2023-02-24 01:45:25,986:INFO:_display_container: 2
2023-02-24 01:45:25,988:INFO:BayesianRidge()
2023-02-24 01:45:25,988:INFO:compare_models() successfully completed......................................
2023-02-24 01:45:42,361:INFO:PyCaret RegressionExperiment
2023-02-24 01:45:42,362:INFO:Logging name: reg-default-name
2023-02-24 01:45:42,362:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-24 01:45:42,362:INFO:version 3.0.0.rc9
2023-02-24 01:45:42,362:INFO:Initializing setup()
2023-02-24 01:45:42,362:INFO:self.USI: eec7
2023-02-24 01:45:42,362:INFO:self._variable_keys: {'y_test', '_available_plots', 'y', 'exp_name_log', 'y_train', 'log_plots_param', 'exp_id', 'idx', 'X_test', 'seed', 'n_jobs_param', 'gpu_n_jobs_param', 'target_param', 'html_param', 'fold_groups_param', 'X_train', 'transform_target_param', 'logging_param', 'data', 'fold_generator', 'USI', 'X', 'memory', 'fold_shuffle_param', '_ml_usecase', 'pipeline', 'gpu_param'}
2023-02-24 01:45:42,362:INFO:Checking environment
2023-02-24 01:45:42,363:INFO:python_version: 3.10.8
2023-02-24 01:45:42,363:INFO:python_build: ('main', 'Oct 13 2022 10:17:43')
2023-02-24 01:45:42,363:INFO:machine: x86_64
2023-02-24 01:45:42,363:INFO:platform: macOS-12.6.1-x86_64-i386-64bit
2023-02-24 01:45:42,363:INFO:Memory: svmem(total=8589934592, available=3018072064, percent=64.9, used=4505333760, free=18153472, active=3000377344, inactive=2978131968, wired=1504956416)
2023-02-24 01:45:42,363:INFO:Physical Core: 2
2023-02-24 01:45:42,364:INFO:Logical Core: 2
2023-02-24 01:45:42,364:INFO:Checking libraries
2023-02-24 01:45:42,364:INFO:System:
2023-02-24 01:45:42,364:INFO:    python: 3.10.8 (main, Oct 13 2022, 10:17:43) [Clang 14.0.0 (clang-1400.0.29.102)]
2023-02-24 01:45:42,364:INFO:executable: /usr/local/opt/python@3.10/bin/python3.10
2023-02-24 01:45:42,364:INFO:   machine: macOS-12.6.1-x86_64-i386-64bit
2023-02-24 01:45:42,364:INFO:PyCaret required dependencies:
2023-02-24 01:45:42,364:INFO:                 pip: 23.0.1
2023-02-24 01:45:42,364:INFO:          setuptools: 65.4.1
2023-02-24 01:45:42,365:INFO:             pycaret: 3.0.0rc9
2023-02-24 01:45:42,365:INFO:             IPython: 8.10.0
2023-02-24 01:45:42,365:INFO:          ipywidgets: 8.0.4
2023-02-24 01:45:42,365:INFO:                tqdm: 4.64.1
2023-02-24 01:45:42,365:INFO:               numpy: 1.23.5
2023-02-24 01:45:42,365:INFO:              pandas: 1.5.2
2023-02-24 01:45:42,365:INFO:              jinja2: 3.1.2
2023-02-24 01:45:42,365:INFO:               scipy: 1.9.3
2023-02-24 01:45:42,365:INFO:              joblib: 1.2.0
2023-02-24 01:45:42,365:INFO:             sklearn: 1.0.2
2023-02-24 01:45:42,366:INFO:                pyod: 1.0.7
2023-02-24 01:45:42,366:INFO:            imblearn: 0.10.1
2023-02-24 01:45:42,366:INFO:   category_encoders: 2.6.0
2023-02-24 01:45:42,366:INFO:            lightgbm: 3.3.5
2023-02-24 01:45:42,366:INFO:               numba: 0.56.4
2023-02-24 01:45:42,366:INFO:            requests: 2.28.2
2023-02-24 01:45:42,366:INFO:          matplotlib: 3.6.3
2023-02-24 01:45:42,366:INFO:          scikitplot: 0.3.7
2023-02-24 01:45:42,366:INFO:         yellowbrick: 1.5
2023-02-24 01:45:42,366:INFO:              plotly: 5.13.0
2023-02-24 01:45:42,367:INFO:             kaleido: 0.2.1
2023-02-24 01:45:42,367:INFO:         statsmodels: 0.13.5
2023-02-24 01:45:42,367:INFO:              sktime: 0.16.1
2023-02-24 01:45:42,367:INFO:               tbats: 1.1.2
2023-02-24 01:45:42,367:INFO:            pmdarima: 2.0.2
2023-02-24 01:45:42,367:INFO:              psutil: 5.9.4
2023-02-24 01:45:42,367:INFO:PyCaret optional dependencies:
2023-02-24 01:45:42,367:INFO:                shap: Not installed
2023-02-24 01:45:42,367:INFO:           interpret: Not installed
2023-02-24 01:45:42,368:INFO:                umap: Not installed
2023-02-24 01:45:42,368:INFO:    pandas_profiling: 4.0.0
2023-02-24 01:45:42,368:INFO:  explainerdashboard: Not installed
2023-02-24 01:45:42,368:INFO:             autoviz: Not installed
2023-02-24 01:45:42,368:INFO:           fairlearn: Not installed
2023-02-24 01:45:42,368:INFO:             xgboost: Not installed
2023-02-24 01:45:42,368:INFO:            catboost: Not installed
2023-02-24 01:45:42,368:INFO:              kmodes: Not installed
2023-02-24 01:45:42,369:INFO:             mlxtend: Not installed
2023-02-24 01:45:42,369:INFO:       statsforecast: Not installed
2023-02-24 01:45:42,369:INFO:        tune_sklearn: Not installed
2023-02-24 01:45:42,369:INFO:                 ray: Not installed
2023-02-24 01:45:42,369:INFO:            hyperopt: Not installed
2023-02-24 01:45:42,369:INFO:              optuna: Not installed
2023-02-24 01:45:42,369:INFO:               skopt: Not installed
2023-02-24 01:45:42,370:INFO:              mlflow: Not installed
2023-02-24 01:45:42,370:INFO:              gradio: Not installed
2023-02-24 01:45:42,370:INFO:             fastapi: Not installed
2023-02-24 01:45:42,370:INFO:             uvicorn: Not installed
2023-02-24 01:45:42,370:INFO:              m2cgen: Not installed
2023-02-24 01:45:42,370:INFO:           evidently: Not installed
2023-02-24 01:45:42,370:INFO:               fugue: Not installed
2023-02-24 01:45:42,370:INFO:           streamlit: 1.17.0
2023-02-24 01:45:42,370:INFO:             prophet: Not installed
2023-02-24 01:45:42,371:INFO:None
2023-02-24 01:45:42,371:INFO:Set up data.
2023-02-24 01:45:42,384:INFO:Set up train/test split.
2023-02-24 01:45:42,392:INFO:Set up index.
2023-02-24 01:45:42,393:INFO:Set up folding strategy.
2023-02-24 01:45:42,393:INFO:Assigning column types.
2023-02-24 01:45:42,402:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-24 01:45:42,402:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-24 01:45:42,412:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-24 01:45:42,420:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-24 01:45:42,546:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-24 01:45:42,619:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-24 01:45:42,619:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:42,620:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:42,621:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-24 01:45:42,628:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-24 01:45:42,636:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-24 01:45:42,729:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-24 01:45:42,829:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-24 01:45:42,839:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:42,839:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:42,840:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-24 01:45:42,853:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-24 01:45:42,871:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-24 01:45:42,994:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-24 01:45:43,060:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-24 01:45:43,061:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:43,062:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:43,069:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-24 01:45:43,076:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-24 01:45:43,172:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-24 01:45:43,243:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-24 01:45:43,244:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:43,245:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:43,245:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-24 01:45:43,260:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-24 01:45:43,352:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-24 01:45:43,427:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-24 01:45:43,428:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:43,429:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:43,446:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-24 01:45:43,545:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-24 01:45:43,617:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-24 01:45:43,618:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:43,618:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:43,619:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-24 01:45:43,747:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-24 01:45:43,827:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-24 01:45:43,827:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:43,828:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:43,942:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-24 01:45:44,022:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-24 01:45:44,023:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:44,023:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:44,024:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-24 01:45:44,136:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-24 01:45:44,207:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:44,207:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:44,315:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-24 01:45:44,393:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:44,394:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:44,394:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-24 01:45:44,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:44,659:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:44,839:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:44,840:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:44,841:INFO:Preparing preprocessing pipeline...
2023-02-24 01:45:44,842:INFO:Set up simple imputation.
2023-02-24 01:45:44,864:INFO:Finished creating preprocessing pipeline.
2023-02-24 01:45:44,870:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/dq/s9918lj122qb5j_dx_8x106m0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'cp', 'trestbps',
                                             'chol', 'fbs', 'restecg',
                                             'thalach', 'exang', 'oldpeak',
                                             'slope', 'ca', 'thal'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-02-24 01:45:44,871:INFO:Creating final display dataframe.
2023-02-24 01:45:45,032:INFO:Setup _display_container:                     Description             Value
0                    Session id               599
1                        Target            target
2                   Target type        Regression
3           Original data shape         (303, 14)
4        Transformed data shape         (303, 14)
5   Transformed train set shape         (212, 14)
6    Transformed test set shape          (91, 14)
7              Numeric features                13
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              eec7
2023-02-24 01:45:45,250:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:45,251:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:45,436:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:45,438:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:45:45,440:INFO:setup() successfully completed in 3.08s...............
2023-02-24 01:45:45,443:INFO:Initializing compare_models()
2023-02-24 01:45:45,443:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x13102a620>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x13102a620>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-24 01:45:45,443:INFO:Checking exceptions
2023-02-24 01:45:45,446:INFO:Preparing display monitor
2023-02-24 01:45:45,450:INFO:Initializing Linear Regression
2023-02-24 01:45:45,451:INFO:Total runtime is 1.1432170867919923e-05 minutes
2023-02-24 01:45:45,451:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:45,452:INFO:Initializing create_model()
2023-02-24 01:45:45,452:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x13102a620>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131311a20>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:45,452:INFO:Checking exceptions
2023-02-24 01:45:45,452:INFO:Importing libraries
2023-02-24 01:45:45,452:INFO:Copying training dataset
2023-02-24 01:45:45,458:INFO:Defining folds
2023-02-24 01:45:45,460:INFO:Declaring metric variables
2023-02-24 01:45:45,461:INFO:Importing untrained model
2023-02-24 01:45:45,462:INFO:Linear Regression Imported successfully
2023-02-24 01:45:45,463:INFO:Starting cross validation
2023-02-24 01:45:45,464:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:45,895:INFO:Calculating mean and std
2023-02-24 01:45:45,896:INFO:Creating metrics dataframe
2023-02-24 01:45:45,904:INFO:Uploading results into container
2023-02-24 01:45:45,905:INFO:Uploading model into container now
2023-02-24 01:45:45,905:INFO:_master_model_container: 1
2023-02-24 01:45:45,906:INFO:_display_container: 2
2023-02-24 01:45:45,907:INFO:LinearRegression(n_jobs=-1)
2023-02-24 01:45:45,907:INFO:create_model() successfully completed......................................
2023-02-24 01:45:46,045:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:46,045:INFO:Creating metrics dataframe
2023-02-24 01:45:46,055:INFO:Initializing Lasso Regression
2023-02-24 01:45:46,056:INFO:Total runtime is 0.010095282395680744 minutes
2023-02-24 01:45:46,056:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:46,056:INFO:Initializing create_model()
2023-02-24 01:45:46,056:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x13102a620>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131311a20>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:46,056:INFO:Checking exceptions
2023-02-24 01:45:46,057:INFO:Importing libraries
2023-02-24 01:45:46,057:INFO:Copying training dataset
2023-02-24 01:45:46,065:INFO:Defining folds
2023-02-24 01:45:46,066:INFO:Declaring metric variables
2023-02-24 01:45:46,066:INFO:Importing untrained model
2023-02-24 01:45:46,067:INFO:Lasso Regression Imported successfully
2023-02-24 01:45:46,068:INFO:Starting cross validation
2023-02-24 01:45:46,069:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:46,578:INFO:Calculating mean and std
2023-02-24 01:45:46,581:INFO:Creating metrics dataframe
2023-02-24 01:45:46,588:INFO:Uploading results into container
2023-02-24 01:45:46,589:INFO:Uploading model into container now
2023-02-24 01:45:46,589:INFO:_master_model_container: 2
2023-02-24 01:45:46,589:INFO:_display_container: 2
2023-02-24 01:45:46,590:INFO:Lasso(random_state=599)
2023-02-24 01:45:46,590:INFO:create_model() successfully completed......................................
2023-02-24 01:45:46,746:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:46,746:INFO:Creating metrics dataframe
2023-02-24 01:45:46,752:INFO:Initializing Ridge Regression
2023-02-24 01:45:46,753:INFO:Total runtime is 0.02171800136566162 minutes
2023-02-24 01:45:46,754:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:46,755:INFO:Initializing create_model()
2023-02-24 01:45:46,755:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x13102a620>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131311a20>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:46,755:INFO:Checking exceptions
2023-02-24 01:45:46,755:INFO:Importing libraries
2023-02-24 01:45:46,755:INFO:Copying training dataset
2023-02-24 01:45:46,761:INFO:Defining folds
2023-02-24 01:45:46,761:INFO:Declaring metric variables
2023-02-24 01:45:46,761:INFO:Importing untrained model
2023-02-24 01:45:46,762:INFO:Ridge Regression Imported successfully
2023-02-24 01:45:46,766:INFO:Starting cross validation
2023-02-24 01:45:46,768:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:47,140:INFO:Calculating mean and std
2023-02-24 01:45:47,146:INFO:Creating metrics dataframe
2023-02-24 01:45:47,152:INFO:Uploading results into container
2023-02-24 01:45:47,157:INFO:Uploading model into container now
2023-02-24 01:45:47,157:INFO:_master_model_container: 3
2023-02-24 01:45:47,158:INFO:_display_container: 2
2023-02-24 01:45:47,158:INFO:Ridge(random_state=599)
2023-02-24 01:45:47,158:INFO:create_model() successfully completed......................................
2023-02-24 01:45:47,295:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:47,296:INFO:Creating metrics dataframe
2023-02-24 01:45:47,304:INFO:Initializing Elastic Net
2023-02-24 01:45:47,308:INFO:Total runtime is 0.030961402257283527 minutes
2023-02-24 01:45:47,308:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:47,309:INFO:Initializing create_model()
2023-02-24 01:45:47,309:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x13102a620>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131311a20>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:47,309:INFO:Checking exceptions
2023-02-24 01:45:47,309:INFO:Importing libraries
2023-02-24 01:45:47,309:INFO:Copying training dataset
2023-02-24 01:45:47,317:INFO:Defining folds
2023-02-24 01:45:47,317:INFO:Declaring metric variables
2023-02-24 01:45:47,318:INFO:Importing untrained model
2023-02-24 01:45:47,319:INFO:Elastic Net Imported successfully
2023-02-24 01:45:47,319:INFO:Starting cross validation
2023-02-24 01:45:47,321:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:47,699:INFO:Calculating mean and std
2023-02-24 01:45:47,700:INFO:Creating metrics dataframe
2023-02-24 01:45:47,705:INFO:Uploading results into container
2023-02-24 01:45:47,709:INFO:Uploading model into container now
2023-02-24 01:45:47,710:INFO:_master_model_container: 4
2023-02-24 01:45:47,710:INFO:_display_container: 2
2023-02-24 01:45:47,710:INFO:ElasticNet(random_state=599)
2023-02-24 01:45:47,710:INFO:create_model() successfully completed......................................
2023-02-24 01:45:47,899:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:47,899:INFO:Creating metrics dataframe
2023-02-24 01:45:47,916:INFO:Initializing Least Angle Regression
2023-02-24 01:45:47,916:INFO:Total runtime is 0.04110236565272013 minutes
2023-02-24 01:45:47,917:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:47,918:INFO:Initializing create_model()
2023-02-24 01:45:47,918:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x13102a620>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131311a20>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:47,918:INFO:Checking exceptions
2023-02-24 01:45:47,918:INFO:Importing libraries
2023-02-24 01:45:47,918:INFO:Copying training dataset
2023-02-24 01:45:47,933:INFO:Defining folds
2023-02-24 01:45:47,933:INFO:Declaring metric variables
2023-02-24 01:45:47,934:INFO:Importing untrained model
2023-02-24 01:45:47,934:INFO:Least Angle Regression Imported successfully
2023-02-24 01:45:47,935:INFO:Starting cross validation
2023-02-24 01:45:47,937:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:48,027:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:48,054:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:48,067:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:48,070:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:48,336:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:48,381:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:48,562:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:48,631:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:48,631:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:48,683:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:48,716:INFO:Calculating mean and std
2023-02-24 01:45:48,724:INFO:Creating metrics dataframe
2023-02-24 01:45:48,730:INFO:Uploading results into container
2023-02-24 01:45:48,731:INFO:Uploading model into container now
2023-02-24 01:45:48,732:INFO:_master_model_container: 5
2023-02-24 01:45:48,732:INFO:_display_container: 2
2023-02-24 01:45:48,733:INFO:Lars(random_state=599)
2023-02-24 01:45:48,733:INFO:create_model() successfully completed......................................
2023-02-24 01:45:48,932:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:48,932:INFO:Creating metrics dataframe
2023-02-24 01:45:48,946:INFO:Initializing Lasso Least Angle Regression
2023-02-24 01:45:48,946:INFO:Total runtime is 0.05826461712519328 minutes
2023-02-24 01:45:48,946:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:48,946:INFO:Initializing create_model()
2023-02-24 01:45:48,947:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x13102a620>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131311a20>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:48,947:INFO:Checking exceptions
2023-02-24 01:45:48,947:INFO:Importing libraries
2023-02-24 01:45:48,947:INFO:Copying training dataset
2023-02-24 01:45:48,954:INFO:Defining folds
2023-02-24 01:45:48,955:INFO:Declaring metric variables
2023-02-24 01:45:48,956:INFO:Importing untrained model
2023-02-24 01:45:48,957:INFO:Lasso Least Angle Regression Imported successfully
2023-02-24 01:45:48,957:INFO:Starting cross validation
2023-02-24 01:45:48,958:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:49,048:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-24 01:45:49,055:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-24 01:45:49,076:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-24 01:45:49,135:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-24 01:45:49,176:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-24 01:45:49,258:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-24 01:45:49,279:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-24 01:45:49,294:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-24 01:45:49,341:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-24 01:45:49,369:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-24 01:45:49,416:INFO:Calculating mean and std
2023-02-24 01:45:49,417:INFO:Creating metrics dataframe
2023-02-24 01:45:49,425:INFO:Uploading results into container
2023-02-24 01:45:49,429:INFO:Uploading model into container now
2023-02-24 01:45:49,430:INFO:_master_model_container: 6
2023-02-24 01:45:49,430:INFO:_display_container: 2
2023-02-24 01:45:49,431:INFO:LassoLars(random_state=599)
2023-02-24 01:45:49,431:INFO:create_model() successfully completed......................................
2023-02-24 01:45:49,585:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:49,587:INFO:Creating metrics dataframe
2023-02-24 01:45:49,597:INFO:Initializing Orthogonal Matching Pursuit
2023-02-24 01:45:49,598:INFO:Total runtime is 0.06912601788838704 minutes
2023-02-24 01:45:49,598:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:49,598:INFO:Initializing create_model()
2023-02-24 01:45:49,598:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x13102a620>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131311a20>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:49,598:INFO:Checking exceptions
2023-02-24 01:45:49,598:INFO:Importing libraries
2023-02-24 01:45:49,598:INFO:Copying training dataset
2023-02-24 01:45:49,604:INFO:Defining folds
2023-02-24 01:45:49,606:INFO:Declaring metric variables
2023-02-24 01:45:49,606:INFO:Importing untrained model
2023-02-24 01:45:49,612:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-24 01:45:49,613:INFO:Starting cross validation
2023-02-24 01:45:49,614:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:49,690:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:49,700:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:49,736:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:49,748:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:49,828:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:49,875:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:49,887:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:49,902:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:49,949:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:49,975:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-24 01:45:50,003:INFO:Calculating mean and std
2023-02-24 01:45:50,004:INFO:Creating metrics dataframe
2023-02-24 01:45:50,010:INFO:Uploading results into container
2023-02-24 01:45:50,012:INFO:Uploading model into container now
2023-02-24 01:45:50,012:INFO:_master_model_container: 7
2023-02-24 01:45:50,013:INFO:_display_container: 2
2023-02-24 01:45:50,013:INFO:OrthogonalMatchingPursuit()
2023-02-24 01:45:50,013:INFO:create_model() successfully completed......................................
2023-02-24 01:45:50,153:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:50,154:INFO:Creating metrics dataframe
2023-02-24 01:45:50,163:INFO:Initializing Bayesian Ridge
2023-02-24 01:45:50,166:INFO:Total runtime is 0.07860326369603475 minutes
2023-02-24 01:45:50,167:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:50,168:INFO:Initializing create_model()
2023-02-24 01:45:50,168:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x13102a620>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131311a20>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:50,169:INFO:Checking exceptions
2023-02-24 01:45:50,169:INFO:Importing libraries
2023-02-24 01:45:50,169:INFO:Copying training dataset
2023-02-24 01:45:50,175:INFO:Defining folds
2023-02-24 01:45:50,177:INFO:Declaring metric variables
2023-02-24 01:45:50,177:INFO:Importing untrained model
2023-02-24 01:45:50,178:INFO:Bayesian Ridge Imported successfully
2023-02-24 01:45:50,179:INFO:Starting cross validation
2023-02-24 01:45:50,180:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:50,581:INFO:Calculating mean and std
2023-02-24 01:45:50,582:INFO:Creating metrics dataframe
2023-02-24 01:45:50,589:INFO:Uploading results into container
2023-02-24 01:45:50,591:INFO:Uploading model into container now
2023-02-24 01:45:50,592:INFO:_master_model_container: 8
2023-02-24 01:45:50,592:INFO:_display_container: 2
2023-02-24 01:45:50,592:INFO:BayesianRidge()
2023-02-24 01:45:50,593:INFO:create_model() successfully completed......................................
2023-02-24 01:45:50,732:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:50,732:INFO:Creating metrics dataframe
2023-02-24 01:45:50,741:INFO:Initializing Passive Aggressive Regressor
2023-02-24 01:45:50,742:INFO:Total runtime is 0.0881927490234375 minutes
2023-02-24 01:45:50,742:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:50,742:INFO:Initializing create_model()
2023-02-24 01:45:50,743:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x13102a620>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131311a20>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:50,743:INFO:Checking exceptions
2023-02-24 01:45:50,743:INFO:Importing libraries
2023-02-24 01:45:50,743:INFO:Copying training dataset
2023-02-24 01:45:50,751:INFO:Defining folds
2023-02-24 01:45:50,751:INFO:Declaring metric variables
2023-02-24 01:45:50,752:INFO:Importing untrained model
2023-02-24 01:45:50,754:INFO:Passive Aggressive Regressor Imported successfully
2023-02-24 01:45:50,755:INFO:Starting cross validation
2023-02-24 01:45:50,756:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:51,160:INFO:Calculating mean and std
2023-02-24 01:45:51,161:INFO:Creating metrics dataframe
2023-02-24 01:45:51,168:INFO:Uploading results into container
2023-02-24 01:45:51,169:INFO:Uploading model into container now
2023-02-24 01:45:51,169:INFO:_master_model_container: 9
2023-02-24 01:45:51,169:INFO:_display_container: 2
2023-02-24 01:45:51,170:INFO:PassiveAggressiveRegressor(random_state=599)
2023-02-24 01:45:51,170:INFO:create_model() successfully completed......................................
2023-02-24 01:45:51,306:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:51,306:INFO:Creating metrics dataframe
2023-02-24 01:45:51,314:INFO:Initializing Huber Regressor
2023-02-24 01:45:51,315:INFO:Total runtime is 0.09774983326594035 minutes
2023-02-24 01:45:51,316:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:51,316:INFO:Initializing create_model()
2023-02-24 01:45:51,316:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x13102a620>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131311a20>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:51,316:INFO:Checking exceptions
2023-02-24 01:45:51,316:INFO:Importing libraries
2023-02-24 01:45:51,317:INFO:Copying training dataset
2023-02-24 01:45:51,324:INFO:Defining folds
2023-02-24 01:45:51,324:INFO:Declaring metric variables
2023-02-24 01:45:51,324:INFO:Importing untrained model
2023-02-24 01:45:51,325:INFO:Huber Regressor Imported successfully
2023-02-24 01:45:51,326:INFO:Starting cross validation
2023-02-24 01:45:51,327:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:51,493:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-24 01:45:51,527:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-24 01:45:51,535:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-24 01:45:51,574:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-24 01:45:51,706:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-24 01:45:51,752:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-24 01:45:51,829:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-24 01:45:51,891:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-24 01:45:51,965:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-24 01:45:51,983:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-24 01:45:52,011:INFO:Calculating mean and std
2023-02-24 01:45:52,012:INFO:Creating metrics dataframe
2023-02-24 01:45:52,021:INFO:Uploading results into container
2023-02-24 01:45:52,023:INFO:Uploading model into container now
2023-02-24 01:45:52,024:INFO:_master_model_container: 10
2023-02-24 01:45:52,024:INFO:_display_container: 2
2023-02-24 01:45:52,024:INFO:HuberRegressor()
2023-02-24 01:45:52,025:INFO:create_model() successfully completed......................................
2023-02-24 01:45:52,173:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:52,174:INFO:Creating metrics dataframe
2023-02-24 01:45:52,184:INFO:Initializing K Neighbors Regressor
2023-02-24 01:45:52,184:INFO:Total runtime is 0.11223643223444621 minutes
2023-02-24 01:45:52,184:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:52,185:INFO:Initializing create_model()
2023-02-24 01:45:52,185:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x13102a620>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131311a20>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:52,185:INFO:Checking exceptions
2023-02-24 01:45:52,185:INFO:Importing libraries
2023-02-24 01:45:52,185:INFO:Copying training dataset
2023-02-24 01:45:52,195:INFO:Defining folds
2023-02-24 01:45:52,196:INFO:Declaring metric variables
2023-02-24 01:45:52,196:INFO:Importing untrained model
2023-02-24 01:45:52,197:INFO:K Neighbors Regressor Imported successfully
2023-02-24 01:45:52,198:INFO:Starting cross validation
2023-02-24 01:45:52,199:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:52,615:INFO:Calculating mean and std
2023-02-24 01:45:52,617:INFO:Creating metrics dataframe
2023-02-24 01:45:52,624:INFO:Uploading results into container
2023-02-24 01:45:52,625:INFO:Uploading model into container now
2023-02-24 01:45:52,626:INFO:_master_model_container: 11
2023-02-24 01:45:52,626:INFO:_display_container: 2
2023-02-24 01:45:52,627:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-24 01:45:52,627:INFO:create_model() successfully completed......................................
2023-02-24 01:45:52,775:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:52,775:INFO:Creating metrics dataframe
2023-02-24 01:45:52,783:INFO:Initializing Decision Tree Regressor
2023-02-24 01:45:52,783:INFO:Total runtime is 0.12221399943033855 minutes
2023-02-24 01:45:52,783:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:52,783:INFO:Initializing create_model()
2023-02-24 01:45:52,784:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x13102a620>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131311a20>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:52,784:INFO:Checking exceptions
2023-02-24 01:45:52,784:INFO:Importing libraries
2023-02-24 01:45:52,784:INFO:Copying training dataset
2023-02-24 01:45:52,791:INFO:Defining folds
2023-02-24 01:45:52,791:INFO:Declaring metric variables
2023-02-24 01:45:52,792:INFO:Importing untrained model
2023-02-24 01:45:52,792:INFO:Decision Tree Regressor Imported successfully
2023-02-24 01:45:52,793:INFO:Starting cross validation
2023-02-24 01:45:52,794:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:53,220:INFO:Calculating mean and std
2023-02-24 01:45:53,221:INFO:Creating metrics dataframe
2023-02-24 01:45:53,227:INFO:Uploading results into container
2023-02-24 01:45:53,228:INFO:Uploading model into container now
2023-02-24 01:45:53,229:INFO:_master_model_container: 12
2023-02-24 01:45:53,229:INFO:_display_container: 2
2023-02-24 01:45:53,229:INFO:DecisionTreeRegressor(random_state=599)
2023-02-24 01:45:53,229:INFO:create_model() successfully completed......................................
2023-02-24 01:45:53,361:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:53,361:INFO:Creating metrics dataframe
2023-02-24 01:45:53,376:INFO:Initializing Random Forest Regressor
2023-02-24 01:45:53,377:INFO:Total runtime is 0.13210711479187012 minutes
2023-02-24 01:45:53,378:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:53,379:INFO:Initializing create_model()
2023-02-24 01:45:53,379:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x13102a620>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131311a20>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:53,380:INFO:Checking exceptions
2023-02-24 01:45:53,380:INFO:Importing libraries
2023-02-24 01:45:53,380:INFO:Copying training dataset
2023-02-24 01:45:53,389:INFO:Defining folds
2023-02-24 01:45:53,389:INFO:Declaring metric variables
2023-02-24 01:45:53,390:INFO:Importing untrained model
2023-02-24 01:45:53,392:INFO:Random Forest Regressor Imported successfully
2023-02-24 01:45:53,393:INFO:Starting cross validation
2023-02-24 01:45:53,394:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:56,426:INFO:Calculating mean and std
2023-02-24 01:45:56,427:INFO:Creating metrics dataframe
2023-02-24 01:45:56,432:INFO:Uploading results into container
2023-02-24 01:45:56,433:INFO:Uploading model into container now
2023-02-24 01:45:56,434:INFO:_master_model_container: 13
2023-02-24 01:45:56,434:INFO:_display_container: 2
2023-02-24 01:45:56,435:INFO:RandomForestRegressor(n_jobs=-1, random_state=599)
2023-02-24 01:45:56,435:INFO:create_model() successfully completed......................................
2023-02-24 01:45:56,574:INFO:SubProcess create_model() end ==================================
2023-02-24 01:45:56,575:INFO:Creating metrics dataframe
2023-02-24 01:45:56,588:INFO:Initializing Extra Trees Regressor
2023-02-24 01:45:56,588:INFO:Total runtime is 0.18563066720962523 minutes
2023-02-24 01:45:56,588:INFO:SubProcess create_model() called ==================================
2023-02-24 01:45:56,589:INFO:Initializing create_model()
2023-02-24 01:45:56,589:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x13102a620>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131311a20>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:45:56,589:INFO:Checking exceptions
2023-02-24 01:45:56,589:INFO:Importing libraries
2023-02-24 01:45:56,589:INFO:Copying training dataset
2023-02-24 01:45:56,612:INFO:Defining folds
2023-02-24 01:45:56,612:INFO:Declaring metric variables
2023-02-24 01:45:56,613:INFO:Importing untrained model
2023-02-24 01:45:56,615:INFO:Extra Trees Regressor Imported successfully
2023-02-24 01:45:56,615:INFO:Starting cross validation
2023-02-24 01:45:56,616:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:45:59,472:WARNING:/usr/local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:252: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-24 01:45:59,501:WARNING:/usr/local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:252: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-24 01:46:00,992:INFO:Calculating mean and std
2023-02-24 01:46:00,994:INFO:Creating metrics dataframe
2023-02-24 01:46:00,999:INFO:Uploading results into container
2023-02-24 01:46:01,000:INFO:Uploading model into container now
2023-02-24 01:46:01,000:INFO:_master_model_container: 14
2023-02-24 01:46:01,000:INFO:_display_container: 2
2023-02-24 01:46:01,001:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=599)
2023-02-24 01:46:01,001:INFO:create_model() successfully completed......................................
2023-02-24 01:46:01,178:INFO:SubProcess create_model() end ==================================
2023-02-24 01:46:01,179:INFO:Creating metrics dataframe
2023-02-24 01:46:01,187:INFO:Initializing AdaBoost Regressor
2023-02-24 01:46:01,187:INFO:Total runtime is 0.2622857809066772 minutes
2023-02-24 01:46:01,187:INFO:SubProcess create_model() called ==================================
2023-02-24 01:46:01,190:INFO:Initializing create_model()
2023-02-24 01:46:01,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x13102a620>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131311a20>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:46:01,190:INFO:Checking exceptions
2023-02-24 01:46:01,190:INFO:Importing libraries
2023-02-24 01:46:01,190:INFO:Copying training dataset
2023-02-24 01:46:01,196:INFO:Defining folds
2023-02-24 01:46:01,196:INFO:Declaring metric variables
2023-02-24 01:46:01,197:INFO:Importing untrained model
2023-02-24 01:46:01,197:INFO:AdaBoost Regressor Imported successfully
2023-02-24 01:46:01,197:INFO:Starting cross validation
2023-02-24 01:46:01,198:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:46:03,739:INFO:Calculating mean and std
2023-02-24 01:46:03,740:INFO:Creating metrics dataframe
2023-02-24 01:46:03,748:INFO:Uploading results into container
2023-02-24 01:46:03,748:INFO:Uploading model into container now
2023-02-24 01:46:03,749:INFO:_master_model_container: 15
2023-02-24 01:46:03,749:INFO:_display_container: 2
2023-02-24 01:46:03,749:INFO:AdaBoostRegressor(random_state=599)
2023-02-24 01:46:03,749:INFO:create_model() successfully completed......................................
2023-02-24 01:46:04,048:INFO:SubProcess create_model() end ==================================
2023-02-24 01:46:04,048:INFO:Creating metrics dataframe
2023-02-24 01:46:04,059:INFO:Initializing Gradient Boosting Regressor
2023-02-24 01:46:04,059:INFO:Total runtime is 0.3101500352223714 minutes
2023-02-24 01:46:04,060:INFO:SubProcess create_model() called ==================================
2023-02-24 01:46:04,060:INFO:Initializing create_model()
2023-02-24 01:46:04,061:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x13102a620>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131311a20>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:46:04,061:INFO:Checking exceptions
2023-02-24 01:46:04,061:INFO:Importing libraries
2023-02-24 01:46:04,061:INFO:Copying training dataset
2023-02-24 01:46:04,071:INFO:Defining folds
2023-02-24 01:46:04,071:INFO:Declaring metric variables
2023-02-24 01:46:04,072:INFO:Importing untrained model
2023-02-24 01:46:04,073:INFO:Gradient Boosting Regressor Imported successfully
2023-02-24 01:46:04,073:INFO:Starting cross validation
2023-02-24 01:46:04,076:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:46:05,929:WARNING:/usr/local/lib/python3.10/site-packages/pycaret/internal/pipeline.py:252: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-24 01:46:06,930:INFO:Calculating mean and std
2023-02-24 01:46:06,930:INFO:Creating metrics dataframe
2023-02-24 01:46:06,935:INFO:Uploading results into container
2023-02-24 01:46:06,936:INFO:Uploading model into container now
2023-02-24 01:46:06,936:INFO:_master_model_container: 16
2023-02-24 01:46:06,936:INFO:_display_container: 2
2023-02-24 01:46:06,937:INFO:GradientBoostingRegressor(random_state=599)
2023-02-24 01:46:06,937:INFO:create_model() successfully completed......................................
2023-02-24 01:46:07,087:INFO:SubProcess create_model() end ==================================
2023-02-24 01:46:07,088:INFO:Creating metrics dataframe
2023-02-24 01:46:07,099:INFO:Initializing Light Gradient Boosting Machine
2023-02-24 01:46:07,099:INFO:Total runtime is 0.3608153978983561 minutes
2023-02-24 01:46:07,099:INFO:SubProcess create_model() called ==================================
2023-02-24 01:46:07,100:INFO:Initializing create_model()
2023-02-24 01:46:07,100:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x13102a620>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131311a20>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:46:07,100:INFO:Checking exceptions
2023-02-24 01:46:07,100:INFO:Importing libraries
2023-02-24 01:46:07,100:INFO:Copying training dataset
2023-02-24 01:46:07,109:INFO:Defining folds
2023-02-24 01:46:07,110:INFO:Declaring metric variables
2023-02-24 01:46:07,111:INFO:Importing untrained model
2023-02-24 01:46:07,111:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-24 01:46:07,112:INFO:Starting cross validation
2023-02-24 01:46:07,113:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:46:08,451:INFO:Calculating mean and std
2023-02-24 01:46:08,452:INFO:Creating metrics dataframe
2023-02-24 01:46:08,458:INFO:Uploading results into container
2023-02-24 01:46:08,459:INFO:Uploading model into container now
2023-02-24 01:46:08,460:INFO:_master_model_container: 17
2023-02-24 01:46:08,460:INFO:_display_container: 2
2023-02-24 01:46:08,461:INFO:LGBMRegressor(random_state=599)
2023-02-24 01:46:08,461:INFO:create_model() successfully completed......................................
2023-02-24 01:46:08,782:INFO:SubProcess create_model() end ==================================
2023-02-24 01:46:08,783:INFO:Creating metrics dataframe
2023-02-24 01:46:08,803:INFO:Initializing Dummy Regressor
2023-02-24 01:46:08,803:INFO:Total runtime is 0.3892126162846883 minutes
2023-02-24 01:46:08,803:INFO:SubProcess create_model() called ==================================
2023-02-24 01:46:08,803:INFO:Initializing create_model()
2023-02-24 01:46:08,804:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x13102a620>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131311a20>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:46:08,804:INFO:Checking exceptions
2023-02-24 01:46:08,804:INFO:Importing libraries
2023-02-24 01:46:08,804:INFO:Copying training dataset
2023-02-24 01:46:08,852:INFO:Defining folds
2023-02-24 01:46:08,852:INFO:Declaring metric variables
2023-02-24 01:46:08,853:INFO:Importing untrained model
2023-02-24 01:46:08,854:INFO:Dummy Regressor Imported successfully
2023-02-24 01:46:08,854:INFO:Starting cross validation
2023-02-24 01:46:08,856:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:46:09,496:INFO:Calculating mean and std
2023-02-24 01:46:09,497:INFO:Creating metrics dataframe
2023-02-24 01:46:09,503:INFO:Uploading results into container
2023-02-24 01:46:09,504:INFO:Uploading model into container now
2023-02-24 01:46:09,504:INFO:_master_model_container: 18
2023-02-24 01:46:09,504:INFO:_display_container: 2
2023-02-24 01:46:09,505:INFO:DummyRegressor()
2023-02-24 01:46:09,505:INFO:create_model() successfully completed......................................
2023-02-24 01:46:09,668:INFO:SubProcess create_model() end ==================================
2023-02-24 01:46:09,669:INFO:Creating metrics dataframe
2023-02-24 01:46:09,689:INFO:Initializing create_model()
2023-02-24 01:46:09,690:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x13102a620>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:46:09,690:INFO:Checking exceptions
2023-02-24 01:46:09,694:INFO:Importing libraries
2023-02-24 01:46:09,694:INFO:Copying training dataset
2023-02-24 01:46:09,702:INFO:Defining folds
2023-02-24 01:46:09,703:INFO:Declaring metric variables
2023-02-24 01:46:09,703:INFO:Importing untrained model
2023-02-24 01:46:09,703:INFO:Declaring custom model
2023-02-24 01:46:09,704:INFO:Bayesian Ridge Imported successfully
2023-02-24 01:46:09,705:INFO:Cross validation set to False
2023-02-24 01:46:09,705:INFO:Fitting Model
2023-02-24 01:46:09,781:INFO:BayesianRidge()
2023-02-24 01:46:09,781:INFO:create_model() successfully completed......................................
2023-02-24 01:46:10,080:INFO:_master_model_container: 18
2023-02-24 01:46:10,080:INFO:_display_container: 2
2023-02-24 01:46:10,081:INFO:BayesianRidge()
2023-02-24 01:46:10,081:INFO:compare_models() successfully completed......................................
2023-02-24 01:46:10,102:INFO:Initializing save_model()
2023-02-24 01:46:10,104:INFO:save_model(model=BayesianRidge(), model_name=best_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/dq/s9918lj122qb5j_dx_8x106m0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'cp', 'trestbps',
                                             'chol', 'fbs', 'restecg',
                                             'thalach', 'exang', 'oldpeak',
                                             'slope', 'ca', 'thal'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-02-24 01:46:10,104:INFO:Adding model into prep_pipe
2023-02-24 01:46:10,123:INFO:best_model.pkl saved in current working directory
2023-02-24 01:46:10,138:INFO:Pipeline(memory=FastMemory(location=/var/folders/dq/s9918lj122qb5j_dx_8x106m0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'sex', 'cp', 'trestbps',
                                             'chol', 'fbs', 'restecg',
                                             'thalach', 'exang', 'oldpeak',
                                             'slope', 'ca', 'thal'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('trained_model', BayesianRidge())])
2023-02-24 01:46:10,139:INFO:save_model() successfully completed......................................
2023-02-24 01:46:46,356:INFO:PyCaret ClassificationExperiment
2023-02-24 01:46:46,357:INFO:Logging name: clf-default-name
2023-02-24 01:46:46,358:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-02-24 01:46:46,358:INFO:version 3.0.0.rc9
2023-02-24 01:46:46,358:INFO:Initializing setup()
2023-02-24 01:46:46,358:INFO:self.USI: 010f
2023-02-24 01:46:46,358:INFO:self._variable_keys: {'y_test', '_available_plots', 'y', 'exp_name_log', 'y_train', 'log_plots_param', 'is_multiclass', 'exp_id', 'idx', 'X_test', 'seed', 'n_jobs_param', 'gpu_n_jobs_param', 'target_param', 'html_param', 'fold_groups_param', 'X_train', 'logging_param', 'data', 'fold_generator', 'USI', 'X', 'fix_imbalance', 'memory', 'fold_shuffle_param', '_ml_usecase', 'pipeline', 'gpu_param'}
2023-02-24 01:46:46,358:INFO:Checking environment
2023-02-24 01:46:46,358:INFO:python_version: 3.10.8
2023-02-24 01:46:46,358:INFO:python_build: ('main', 'Oct 13 2022 10:17:43')
2023-02-24 01:46:46,358:INFO:machine: x86_64
2023-02-24 01:46:46,358:INFO:platform: macOS-12.6.1-x86_64-i386-64bit
2023-02-24 01:46:46,359:INFO:Memory: svmem(total=8589934592, available=3035074560, percent=64.7, used=4496867328, free=22515712, active=3010764800, inactive=3006808064, wired=1486102528)
2023-02-24 01:46:46,359:INFO:Physical Core: 2
2023-02-24 01:46:46,359:INFO:Logical Core: 2
2023-02-24 01:46:46,359:INFO:Checking libraries
2023-02-24 01:46:46,360:INFO:System:
2023-02-24 01:46:46,360:INFO:    python: 3.10.8 (main, Oct 13 2022, 10:17:43) [Clang 14.0.0 (clang-1400.0.29.102)]
2023-02-24 01:46:46,360:INFO:executable: /usr/local/opt/python@3.10/bin/python3.10
2023-02-24 01:46:46,361:INFO:   machine: macOS-12.6.1-x86_64-i386-64bit
2023-02-24 01:46:46,361:INFO:PyCaret required dependencies:
2023-02-24 01:46:46,361:INFO:                 pip: 23.0.1
2023-02-24 01:46:46,361:INFO:          setuptools: 65.4.1
2023-02-24 01:46:46,361:INFO:             pycaret: 3.0.0rc9
2023-02-24 01:46:46,361:INFO:             IPython: 8.10.0
2023-02-24 01:46:46,361:INFO:          ipywidgets: 8.0.4
2023-02-24 01:46:46,362:INFO:                tqdm: 4.64.1
2023-02-24 01:46:46,362:INFO:               numpy: 1.23.5
2023-02-24 01:46:46,362:INFO:              pandas: 1.5.2
2023-02-24 01:46:46,362:INFO:              jinja2: 3.1.2
2023-02-24 01:46:46,362:INFO:               scipy: 1.9.3
2023-02-24 01:46:46,362:INFO:              joblib: 1.2.0
2023-02-24 01:46:46,362:INFO:             sklearn: 1.0.2
2023-02-24 01:46:46,362:INFO:                pyod: 1.0.7
2023-02-24 01:46:46,363:INFO:            imblearn: 0.10.1
2023-02-24 01:46:46,363:INFO:   category_encoders: 2.6.0
2023-02-24 01:46:46,363:INFO:            lightgbm: 3.3.5
2023-02-24 01:46:46,363:INFO:               numba: 0.56.4
2023-02-24 01:46:46,364:INFO:            requests: 2.28.2
2023-02-24 01:46:46,364:INFO:          matplotlib: 3.6.3
2023-02-24 01:46:46,364:INFO:          scikitplot: 0.3.7
2023-02-24 01:46:46,364:INFO:         yellowbrick: 1.5
2023-02-24 01:46:46,364:INFO:              plotly: 5.13.0
2023-02-24 01:46:46,364:INFO:             kaleido: 0.2.1
2023-02-24 01:46:46,364:INFO:         statsmodels: 0.13.5
2023-02-24 01:46:46,365:INFO:              sktime: 0.16.1
2023-02-24 01:46:46,365:INFO:               tbats: 1.1.2
2023-02-24 01:46:46,365:INFO:            pmdarima: 2.0.2
2023-02-24 01:46:46,365:INFO:              psutil: 5.9.4
2023-02-24 01:46:46,365:INFO:PyCaret optional dependencies:
2023-02-24 01:46:46,366:INFO:                shap: Not installed
2023-02-24 01:46:46,366:INFO:           interpret: Not installed
2023-02-24 01:46:46,366:INFO:                umap: Not installed
2023-02-24 01:46:46,366:INFO:    pandas_profiling: 4.0.0
2023-02-24 01:46:46,367:INFO:  explainerdashboard: Not installed
2023-02-24 01:46:46,367:INFO:             autoviz: Not installed
2023-02-24 01:46:46,367:INFO:           fairlearn: Not installed
2023-02-24 01:46:46,367:INFO:             xgboost: Not installed
2023-02-24 01:46:46,367:INFO:            catboost: Not installed
2023-02-24 01:46:46,367:INFO:              kmodes: Not installed
2023-02-24 01:46:46,367:INFO:             mlxtend: Not installed
2023-02-24 01:46:46,367:INFO:       statsforecast: Not installed
2023-02-24 01:46:46,367:INFO:        tune_sklearn: Not installed
2023-02-24 01:46:46,367:INFO:                 ray: Not installed
2023-02-24 01:46:46,367:INFO:            hyperopt: Not installed
2023-02-24 01:46:46,367:INFO:              optuna: Not installed
2023-02-24 01:46:46,368:INFO:               skopt: Not installed
2023-02-24 01:46:46,368:INFO:              mlflow: Not installed
2023-02-24 01:46:46,368:INFO:              gradio: Not installed
2023-02-24 01:46:46,368:INFO:             fastapi: Not installed
2023-02-24 01:46:46,368:INFO:             uvicorn: Not installed
2023-02-24 01:46:46,368:INFO:              m2cgen: Not installed
2023-02-24 01:46:46,368:INFO:           evidently: Not installed
2023-02-24 01:46:46,368:INFO:               fugue: Not installed
2023-02-24 01:46:46,368:INFO:           streamlit: 1.17.0
2023-02-24 01:46:46,368:INFO:             prophet: Not installed
2023-02-24 01:46:46,368:INFO:None
2023-02-24 01:46:46,368:INFO:Set up data.
2023-02-24 01:46:46,385:INFO:Set up train/test split.
2023-02-24 01:46:46,403:INFO:Set up index.
2023-02-24 01:46:46,403:INFO:Set up folding strategy.
2023-02-24 01:46:46,403:INFO:Assigning column types.
2023-02-24 01:46:46,420:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-24 01:46:46,499:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-24 01:46:46,503:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-24 01:46:46,547:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:46:46,547:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:46:46,616:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-24 01:46:46,618:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-24 01:46:46,659:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:46:46,660:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:46:46,660:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-24 01:46:46,724:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-24 01:46:46,765:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:46:46,766:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:46:46,834:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-24 01:46:46,874:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:46:46,875:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:46:46,875:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-02-24 01:46:46,983:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:46:46,983:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:46:47,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:46:47,091:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:46:47,092:INFO:Preparing preprocessing pipeline...
2023-02-24 01:46:47,096:INFO:Set up simple imputation.
2023-02-24 01:46:47,115:INFO:Finished creating preprocessing pipeline.
2023-02-24 01:46:47,119:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/dq/s9918lj122qb5j_dx_8x106m0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'sex', 'cp', 'trestbps',
                                             'chol', 'fbs', 'restecg',
                                             'thalach', 'exang', 'oldpeak',
                                             'slope', 'ca', 'thal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-02-24 01:46:47,119:INFO:Creating final display dataframe.
2023-02-24 01:46:47,252:INFO:Setup _display_container:                     Description             Value
0                    Session id              6140
1                        Target            target
2                   Target type            Binary
3           Original data shape         (303, 14)
4        Transformed data shape         (303, 14)
5   Transformed train set shape         (212, 14)
6    Transformed test set shape          (91, 14)
7              Numeric features                13
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              010f
2023-02-24 01:46:47,368:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:46:47,368:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:46:47,482:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:46:47,482:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:46:47,484:INFO:setup() successfully completed in 1.13s...............
2023-02-24 01:46:47,488:INFO:Initializing compare_models()
2023-02-24 01:46:47,488:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x130ad5c00>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x130ad5c00>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-02-24 01:46:47,489:INFO:Checking exceptions
2023-02-24 01:46:47,496:INFO:Preparing display monitor
2023-02-24 01:46:47,500:INFO:Initializing Logistic Regression
2023-02-24 01:46:47,500:INFO:Total runtime is 2.6146570841471354e-06 minutes
2023-02-24 01:46:47,500:INFO:SubProcess create_model() called ==================================
2023-02-24 01:46:47,501:INFO:Initializing create_model()
2023-02-24 01:46:47,501:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x130ad5c00>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x130ad4400>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:46:47,501:INFO:Checking exceptions
2023-02-24 01:46:47,501:INFO:Importing libraries
2023-02-24 01:46:47,502:INFO:Copying training dataset
2023-02-24 01:46:47,574:INFO:Defining folds
2023-02-24 01:46:47,574:INFO:Declaring metric variables
2023-02-24 01:46:47,574:INFO:Importing untrained model
2023-02-24 01:46:47,574:INFO:Logistic Regression Imported successfully
2023-02-24 01:46:47,575:INFO:Starting cross validation
2023-02-24 01:46:47,578:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:46:49,487:INFO:Calculating mean and std
2023-02-24 01:46:49,488:INFO:Creating metrics dataframe
2023-02-24 01:46:49,493:INFO:Uploading results into container
2023-02-24 01:46:49,494:INFO:Uploading model into container now
2023-02-24 01:46:49,495:INFO:_master_model_container: 1
2023-02-24 01:46:49,495:INFO:_display_container: 2
2023-02-24 01:46:49,496:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6140, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-02-24 01:46:49,496:INFO:create_model() successfully completed......................................
2023-02-24 01:46:49,656:INFO:SubProcess create_model() end ==================================
2023-02-24 01:46:49,656:INFO:Creating metrics dataframe
2023-02-24 01:46:49,667:INFO:Initializing K Neighbors Classifier
2023-02-24 01:46:49,667:INFO:Total runtime is 0.036113580067952476 minutes
2023-02-24 01:46:49,667:INFO:SubProcess create_model() called ==================================
2023-02-24 01:46:49,668:INFO:Initializing create_model()
2023-02-24 01:46:49,668:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x130ad5c00>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x130ad4400>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:46:49,668:INFO:Checking exceptions
2023-02-24 01:46:49,668:INFO:Importing libraries
2023-02-24 01:46:49,668:INFO:Copying training dataset
2023-02-24 01:46:49,676:INFO:Defining folds
2023-02-24 01:46:49,676:INFO:Declaring metric variables
2023-02-24 01:46:49,676:INFO:Importing untrained model
2023-02-24 01:46:49,677:INFO:K Neighbors Classifier Imported successfully
2023-02-24 01:46:49,677:INFO:Starting cross validation
2023-02-24 01:46:49,679:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:46:49,833:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-24 01:46:49,849:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-24 01:46:49,859:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-24 01:46:49,877:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-24 01:46:50,102:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-24 01:46:50,125:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-24 01:46:50,135:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-24 01:46:50,146:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-24 01:46:50,256:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-24 01:46:50,267:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-24 01:46:50,299:INFO:Calculating mean and std
2023-02-24 01:46:50,300:INFO:Creating metrics dataframe
2023-02-24 01:46:50,305:INFO:Uploading results into container
2023-02-24 01:46:50,306:INFO:Uploading model into container now
2023-02-24 01:46:50,307:INFO:_master_model_container: 2
2023-02-24 01:46:50,307:INFO:_display_container: 2
2023-02-24 01:46:50,308:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-02-24 01:46:50,308:INFO:create_model() successfully completed......................................
2023-02-24 01:46:50,439:INFO:SubProcess create_model() end ==================================
2023-02-24 01:46:50,439:INFO:Creating metrics dataframe
2023-02-24 01:46:50,446:INFO:Initializing Naive Bayes
2023-02-24 01:46:50,446:INFO:Total runtime is 0.04910049438476563 minutes
2023-02-24 01:46:50,446:INFO:SubProcess create_model() called ==================================
2023-02-24 01:46:50,447:INFO:Initializing create_model()
2023-02-24 01:46:50,447:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x130ad5c00>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x130ad4400>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:46:50,447:INFO:Checking exceptions
2023-02-24 01:46:50,447:INFO:Importing libraries
2023-02-24 01:46:50,447:INFO:Copying training dataset
2023-02-24 01:46:50,452:INFO:Defining folds
2023-02-24 01:46:50,452:INFO:Declaring metric variables
2023-02-24 01:46:50,453:INFO:Importing untrained model
2023-02-24 01:46:50,453:INFO:Naive Bayes Imported successfully
2023-02-24 01:46:50,454:INFO:Starting cross validation
2023-02-24 01:46:50,456:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:46:50,879:INFO:Calculating mean and std
2023-02-24 01:46:50,880:INFO:Creating metrics dataframe
2023-02-24 01:46:50,885:INFO:Uploading results into container
2023-02-24 01:46:50,886:INFO:Uploading model into container now
2023-02-24 01:46:50,887:INFO:_master_model_container: 3
2023-02-24 01:46:50,887:INFO:_display_container: 2
2023-02-24 01:46:50,887:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-02-24 01:46:50,887:INFO:create_model() successfully completed......................................
2023-02-24 01:46:51,016:INFO:SubProcess create_model() end ==================================
2023-02-24 01:46:51,016:INFO:Creating metrics dataframe
2023-02-24 01:46:51,023:INFO:Initializing Decision Tree Classifier
2023-02-24 01:46:51,023:INFO:Total runtime is 0.05872264703114828 minutes
2023-02-24 01:46:51,024:INFO:SubProcess create_model() called ==================================
2023-02-24 01:46:51,024:INFO:Initializing create_model()
2023-02-24 01:46:51,024:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x130ad5c00>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x130ad4400>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:46:51,024:INFO:Checking exceptions
2023-02-24 01:46:51,024:INFO:Importing libraries
2023-02-24 01:46:51,024:INFO:Copying training dataset
2023-02-24 01:46:51,030:INFO:Defining folds
2023-02-24 01:46:51,030:INFO:Declaring metric variables
2023-02-24 01:46:51,030:INFO:Importing untrained model
2023-02-24 01:46:51,031:INFO:Decision Tree Classifier Imported successfully
2023-02-24 01:46:51,031:INFO:Starting cross validation
2023-02-24 01:46:51,033:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:46:51,574:INFO:Calculating mean and std
2023-02-24 01:46:51,575:INFO:Creating metrics dataframe
2023-02-24 01:46:51,584:INFO:Uploading results into container
2023-02-24 01:46:51,585:INFO:Uploading model into container now
2023-02-24 01:46:51,585:INFO:_master_model_container: 4
2023-02-24 01:46:51,585:INFO:_display_container: 2
2023-02-24 01:46:51,586:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6140, splitter='best')
2023-02-24 01:46:51,586:INFO:create_model() successfully completed......................................
2023-02-24 01:46:51,722:INFO:SubProcess create_model() end ==================================
2023-02-24 01:46:51,723:INFO:Creating metrics dataframe
2023-02-24 01:46:51,732:INFO:Initializing SVM - Linear Kernel
2023-02-24 01:46:51,732:INFO:Total runtime is 0.07053066094716391 minutes
2023-02-24 01:46:51,732:INFO:SubProcess create_model() called ==================================
2023-02-24 01:46:51,732:INFO:Initializing create_model()
2023-02-24 01:46:51,733:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x130ad5c00>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x130ad4400>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:46:51,733:INFO:Checking exceptions
2023-02-24 01:46:51,733:INFO:Importing libraries
2023-02-24 01:46:51,733:INFO:Copying training dataset
2023-02-24 01:46:51,737:INFO:Defining folds
2023-02-24 01:46:51,738:INFO:Declaring metric variables
2023-02-24 01:46:51,738:INFO:Importing untrained model
2023-02-24 01:46:51,739:INFO:SVM - Linear Kernel Imported successfully
2023-02-24 01:46:51,739:INFO:Starting cross validation
2023-02-24 01:46:51,740:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:46:51,862:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-24 01:46:52,082:INFO:Calculating mean and std
2023-02-24 01:46:52,083:INFO:Creating metrics dataframe
2023-02-24 01:46:52,088:INFO:Uploading results into container
2023-02-24 01:46:52,090:INFO:Uploading model into container now
2023-02-24 01:46:52,090:INFO:_master_model_container: 5
2023-02-24 01:46:52,090:INFO:_display_container: 2
2023-02-24 01:46:52,091:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6140, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-24 01:46:52,091:INFO:create_model() successfully completed......................................
2023-02-24 01:46:52,220:INFO:SubProcess create_model() end ==================================
2023-02-24 01:46:52,220:INFO:Creating metrics dataframe
2023-02-24 01:46:52,227:INFO:Initializing Ridge Classifier
2023-02-24 01:46:52,227:INFO:Total runtime is 0.0787834962209066 minutes
2023-02-24 01:46:52,227:INFO:SubProcess create_model() called ==================================
2023-02-24 01:46:52,228:INFO:Initializing create_model()
2023-02-24 01:46:52,228:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x130ad5c00>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x130ad4400>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:46:52,228:INFO:Checking exceptions
2023-02-24 01:46:52,228:INFO:Importing libraries
2023-02-24 01:46:52,228:INFO:Copying training dataset
2023-02-24 01:46:52,233:INFO:Defining folds
2023-02-24 01:46:52,234:INFO:Declaring metric variables
2023-02-24 01:46:52,234:INFO:Importing untrained model
2023-02-24 01:46:52,235:INFO:Ridge Classifier Imported successfully
2023-02-24 01:46:52,235:INFO:Starting cross validation
2023-02-24 01:46:52,236:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:46:52,604:INFO:Calculating mean and std
2023-02-24 01:46:52,605:INFO:Creating metrics dataframe
2023-02-24 01:46:52,612:INFO:Uploading results into container
2023-02-24 01:46:52,613:INFO:Uploading model into container now
2023-02-24 01:46:52,613:INFO:_master_model_container: 6
2023-02-24 01:46:52,613:INFO:_display_container: 2
2023-02-24 01:46:52,614:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=6140, solver='auto', tol=0.001)
2023-02-24 01:46:52,614:INFO:create_model() successfully completed......................................
2023-02-24 01:46:52,740:INFO:SubProcess create_model() end ==================================
2023-02-24 01:46:52,740:INFO:Creating metrics dataframe
2023-02-24 01:46:52,747:INFO:Initializing Random Forest Classifier
2023-02-24 01:46:52,748:INFO:Total runtime is 0.08745716412862144 minutes
2023-02-24 01:46:52,748:INFO:SubProcess create_model() called ==================================
2023-02-24 01:46:52,748:INFO:Initializing create_model()
2023-02-24 01:46:52,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x130ad5c00>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x130ad4400>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:46:52,748:INFO:Checking exceptions
2023-02-24 01:46:52,748:INFO:Importing libraries
2023-02-24 01:46:52,748:INFO:Copying training dataset
2023-02-24 01:46:52,754:INFO:Defining folds
2023-02-24 01:46:52,754:INFO:Declaring metric variables
2023-02-24 01:46:52,755:INFO:Importing untrained model
2023-02-24 01:46:52,756:INFO:Random Forest Classifier Imported successfully
2023-02-24 01:46:52,756:INFO:Starting cross validation
2023-02-24 01:46:52,757:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:46:56,334:INFO:Calculating mean and std
2023-02-24 01:46:56,335:INFO:Creating metrics dataframe
2023-02-24 01:46:56,340:INFO:Uploading results into container
2023-02-24 01:46:56,341:INFO:Uploading model into container now
2023-02-24 01:46:56,342:INFO:_master_model_container: 7
2023-02-24 01:46:56,342:INFO:_display_container: 2
2023-02-24 01:46:56,342:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6140, verbose=0, warm_start=False)
2023-02-24 01:46:56,342:INFO:create_model() successfully completed......................................
2023-02-24 01:46:56,469:INFO:SubProcess create_model() end ==================================
2023-02-24 01:46:56,469:INFO:Creating metrics dataframe
2023-02-24 01:46:56,477:INFO:Initializing Quadratic Discriminant Analysis
2023-02-24 01:46:56,477:INFO:Total runtime is 0.14961484670639041 minutes
2023-02-24 01:46:56,477:INFO:SubProcess create_model() called ==================================
2023-02-24 01:46:56,478:INFO:Initializing create_model()
2023-02-24 01:46:56,478:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x130ad5c00>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x130ad4400>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:46:56,478:INFO:Checking exceptions
2023-02-24 01:46:56,478:INFO:Importing libraries
2023-02-24 01:46:56,478:INFO:Copying training dataset
2023-02-24 01:46:56,483:INFO:Defining folds
2023-02-24 01:46:56,483:INFO:Declaring metric variables
2023-02-24 01:46:56,483:INFO:Importing untrained model
2023-02-24 01:46:56,484:INFO:Quadratic Discriminant Analysis Imported successfully
2023-02-24 01:46:56,484:INFO:Starting cross validation
2023-02-24 01:46:56,485:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:46:56,892:INFO:Calculating mean and std
2023-02-24 01:46:56,892:INFO:Creating metrics dataframe
2023-02-24 01:46:56,898:INFO:Uploading results into container
2023-02-24 01:46:56,898:INFO:Uploading model into container now
2023-02-24 01:46:56,899:INFO:_master_model_container: 8
2023-02-24 01:46:56,899:INFO:_display_container: 2
2023-02-24 01:46:56,899:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-02-24 01:46:56,899:INFO:create_model() successfully completed......................................
2023-02-24 01:46:57,029:INFO:SubProcess create_model() end ==================================
2023-02-24 01:46:57,030:INFO:Creating metrics dataframe
2023-02-24 01:46:57,036:INFO:Initializing Ada Boost Classifier
2023-02-24 01:46:57,036:INFO:Total runtime is 0.15893896420796716 minutes
2023-02-24 01:46:57,037:INFO:SubProcess create_model() called ==================================
2023-02-24 01:46:57,037:INFO:Initializing create_model()
2023-02-24 01:46:57,037:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x130ad5c00>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x130ad4400>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:46:57,037:INFO:Checking exceptions
2023-02-24 01:46:57,037:INFO:Importing libraries
2023-02-24 01:46:57,037:INFO:Copying training dataset
2023-02-24 01:46:57,042:INFO:Defining folds
2023-02-24 01:46:57,042:INFO:Declaring metric variables
2023-02-24 01:46:57,043:INFO:Importing untrained model
2023-02-24 01:46:57,044:INFO:Ada Boost Classifier Imported successfully
2023-02-24 01:46:57,044:INFO:Starting cross validation
2023-02-24 01:46:57,045:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:46:59,052:INFO:Calculating mean and std
2023-02-24 01:46:59,053:INFO:Creating metrics dataframe
2023-02-24 01:46:59,058:INFO:Uploading results into container
2023-02-24 01:46:59,059:INFO:Uploading model into container now
2023-02-24 01:46:59,060:INFO:_master_model_container: 9
2023-02-24 01:46:59,060:INFO:_display_container: 2
2023-02-24 01:46:59,060:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=6140)
2023-02-24 01:46:59,060:INFO:create_model() successfully completed......................................
2023-02-24 01:46:59,189:INFO:SubProcess create_model() end ==================================
2023-02-24 01:46:59,189:INFO:Creating metrics dataframe
2023-02-24 01:46:59,197:INFO:Initializing Gradient Boosting Classifier
2023-02-24 01:46:59,198:INFO:Total runtime is 0.19495896100997928 minutes
2023-02-24 01:46:59,198:INFO:SubProcess create_model() called ==================================
2023-02-24 01:46:59,198:INFO:Initializing create_model()
2023-02-24 01:46:59,198:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x130ad5c00>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x130ad4400>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:46:59,198:INFO:Checking exceptions
2023-02-24 01:46:59,198:INFO:Importing libraries
2023-02-24 01:46:59,198:INFO:Copying training dataset
2023-02-24 01:46:59,203:INFO:Defining folds
2023-02-24 01:46:59,204:INFO:Declaring metric variables
2023-02-24 01:46:59,204:INFO:Importing untrained model
2023-02-24 01:46:59,206:INFO:Gradient Boosting Classifier Imported successfully
2023-02-24 01:46:59,207:INFO:Starting cross validation
2023-02-24 01:46:59,207:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:47:01,244:INFO:Calculating mean and std
2023-02-24 01:47:01,246:INFO:Creating metrics dataframe
2023-02-24 01:47:01,252:INFO:Uploading results into container
2023-02-24 01:47:01,253:INFO:Uploading model into container now
2023-02-24 01:47:01,253:INFO:_master_model_container: 10
2023-02-24 01:47:01,254:INFO:_display_container: 2
2023-02-24 01:47:01,254:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6140, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-24 01:47:01,254:INFO:create_model() successfully completed......................................
2023-02-24 01:47:01,381:INFO:SubProcess create_model() end ==================================
2023-02-24 01:47:01,381:INFO:Creating metrics dataframe
2023-02-24 01:47:01,389:INFO:Initializing Linear Discriminant Analysis
2023-02-24 01:47:01,389:INFO:Total runtime is 0.2314786275227865 minutes
2023-02-24 01:47:01,389:INFO:SubProcess create_model() called ==================================
2023-02-24 01:47:01,389:INFO:Initializing create_model()
2023-02-24 01:47:01,390:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x130ad5c00>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x130ad4400>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:47:01,390:INFO:Checking exceptions
2023-02-24 01:47:01,390:INFO:Importing libraries
2023-02-24 01:47:01,390:INFO:Copying training dataset
2023-02-24 01:47:01,395:INFO:Defining folds
2023-02-24 01:47:01,396:INFO:Declaring metric variables
2023-02-24 01:47:01,396:INFO:Importing untrained model
2023-02-24 01:47:01,398:INFO:Linear Discriminant Analysis Imported successfully
2023-02-24 01:47:01,398:INFO:Starting cross validation
2023-02-24 01:47:01,399:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:47:01,823:INFO:Calculating mean and std
2023-02-24 01:47:01,824:INFO:Creating metrics dataframe
2023-02-24 01:47:01,831:INFO:Uploading results into container
2023-02-24 01:47:01,832:INFO:Uploading model into container now
2023-02-24 01:47:01,832:INFO:_master_model_container: 11
2023-02-24 01:47:01,832:INFO:_display_container: 2
2023-02-24 01:47:01,833:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-02-24 01:47:01,833:INFO:create_model() successfully completed......................................
2023-02-24 01:47:01,958:INFO:SubProcess create_model() end ==================================
2023-02-24 01:47:01,958:INFO:Creating metrics dataframe
2023-02-24 01:47:01,967:INFO:Initializing Extra Trees Classifier
2023-02-24 01:47:01,967:INFO:Total runtime is 0.2411189953486125 minutes
2023-02-24 01:47:01,967:INFO:SubProcess create_model() called ==================================
2023-02-24 01:47:01,968:INFO:Initializing create_model()
2023-02-24 01:47:01,968:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x130ad5c00>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x130ad4400>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:47:01,968:INFO:Checking exceptions
2023-02-24 01:47:01,968:INFO:Importing libraries
2023-02-24 01:47:01,968:INFO:Copying training dataset
2023-02-24 01:47:01,974:INFO:Defining folds
2023-02-24 01:47:01,974:INFO:Declaring metric variables
2023-02-24 01:47:01,974:INFO:Importing untrained model
2023-02-24 01:47:01,975:INFO:Extra Trees Classifier Imported successfully
2023-02-24 01:47:01,975:INFO:Starting cross validation
2023-02-24 01:47:01,976:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:47:05,258:INFO:Calculating mean and std
2023-02-24 01:47:05,259:INFO:Creating metrics dataframe
2023-02-24 01:47:05,265:INFO:Uploading results into container
2023-02-24 01:47:05,266:INFO:Uploading model into container now
2023-02-24 01:47:05,266:INFO:_master_model_container: 12
2023-02-24 01:47:05,267:INFO:_display_container: 2
2023-02-24 01:47:05,267:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6140, verbose=0, warm_start=False)
2023-02-24 01:47:05,267:INFO:create_model() successfully completed......................................
2023-02-24 01:47:05,393:INFO:SubProcess create_model() end ==================================
2023-02-24 01:47:05,393:INFO:Creating metrics dataframe
2023-02-24 01:47:05,400:INFO:Initializing Light Gradient Boosting Machine
2023-02-24 01:47:05,400:INFO:Total runtime is 0.2983367284138998 minutes
2023-02-24 01:47:05,401:INFO:SubProcess create_model() called ==================================
2023-02-24 01:47:05,401:INFO:Initializing create_model()
2023-02-24 01:47:05,401:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x130ad5c00>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x130ad4400>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:47:05,401:INFO:Checking exceptions
2023-02-24 01:47:05,401:INFO:Importing libraries
2023-02-24 01:47:05,401:INFO:Copying training dataset
2023-02-24 01:47:05,406:INFO:Defining folds
2023-02-24 01:47:05,407:INFO:Declaring metric variables
2023-02-24 01:47:05,407:INFO:Importing untrained model
2023-02-24 01:47:05,408:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-24 01:47:05,408:INFO:Starting cross validation
2023-02-24 01:47:05,409:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:47:05,951:INFO:Calculating mean and std
2023-02-24 01:47:05,952:INFO:Creating metrics dataframe
2023-02-24 01:47:05,958:INFO:Uploading results into container
2023-02-24 01:47:05,959:INFO:Uploading model into container now
2023-02-24 01:47:05,959:INFO:_master_model_container: 13
2023-02-24 01:47:05,959:INFO:_display_container: 2
2023-02-24 01:47:05,960:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6140, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-24 01:47:05,960:INFO:create_model() successfully completed......................................
2023-02-24 01:47:06,087:INFO:SubProcess create_model() end ==================================
2023-02-24 01:47:06,087:INFO:Creating metrics dataframe
2023-02-24 01:47:06,096:INFO:Initializing Dummy Classifier
2023-02-24 01:47:06,096:INFO:Total runtime is 0.30993399620056156 minutes
2023-02-24 01:47:06,096:INFO:SubProcess create_model() called ==================================
2023-02-24 01:47:06,097:INFO:Initializing create_model()
2023-02-24 01:47:06,097:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x130ad5c00>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x130ad4400>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:47:06,097:INFO:Checking exceptions
2023-02-24 01:47:06,097:INFO:Importing libraries
2023-02-24 01:47:06,097:INFO:Copying training dataset
2023-02-24 01:47:06,103:INFO:Defining folds
2023-02-24 01:47:06,103:INFO:Declaring metric variables
2023-02-24 01:47:06,104:INFO:Importing untrained model
2023-02-24 01:47:06,105:INFO:Dummy Classifier Imported successfully
2023-02-24 01:47:06,105:INFO:Starting cross validation
2023-02-24 01:47:06,106:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:47:06,490:INFO:Calculating mean and std
2023-02-24 01:47:06,491:INFO:Creating metrics dataframe
2023-02-24 01:47:06,497:INFO:Uploading results into container
2023-02-24 01:47:06,498:INFO:Uploading model into container now
2023-02-24 01:47:06,499:INFO:_master_model_container: 14
2023-02-24 01:47:06,499:INFO:_display_container: 2
2023-02-24 01:47:06,499:INFO:DummyClassifier(constant=None, random_state=6140, strategy='prior')
2023-02-24 01:47:06,499:INFO:create_model() successfully completed......................................
2023-02-24 01:47:06,626:INFO:SubProcess create_model() end ==================================
2023-02-24 01:47:06,626:INFO:Creating metrics dataframe
2023-02-24 01:47:06,638:INFO:Initializing create_model()
2023-02-24 01:47:06,638:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x130ad5c00>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6140, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:47:06,638:INFO:Checking exceptions
2023-02-24 01:47:06,639:INFO:Importing libraries
2023-02-24 01:47:06,639:INFO:Copying training dataset
2023-02-24 01:47:06,644:INFO:Defining folds
2023-02-24 01:47:06,645:INFO:Declaring metric variables
2023-02-24 01:47:06,645:INFO:Importing untrained model
2023-02-24 01:47:06,645:INFO:Declaring custom model
2023-02-24 01:47:06,646:INFO:Logistic Regression Imported successfully
2023-02-24 01:47:06,647:INFO:Cross validation set to False
2023-02-24 01:47:06,647:INFO:Fitting Model
2023-02-24 01:47:06,831:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6140, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-02-24 01:47:06,831:INFO:create_model() successfully completed......................................
2023-02-24 01:47:06,979:INFO:_master_model_container: 14
2023-02-24 01:47:06,979:INFO:_display_container: 2
2023-02-24 01:47:06,980:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6140, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-02-24 01:47:06,980:INFO:compare_models() successfully completed......................................
2023-02-24 01:47:06,988:INFO:Initializing save_model()
2023-02-24 01:47:06,988:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6140, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=best_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/dq/s9918lj122qb5j_dx_8x106m0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'sex', 'cp', 'trestbps',
                                             'chol', 'fbs', 'restecg',
                                             'thalach', 'exang', 'oldpeak',
                                             'slope', 'ca', 'thal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-02-24 01:47:06,988:INFO:Adding model into prep_pipe
2023-02-24 01:47:06,993:INFO:best_model.pkl saved in current working directory
2023-02-24 01:47:07,000:INFO:Pipeline(memory=FastMemory(location=/var/folders/dq/s9918lj122qb5j_dx_8x106m0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'sex', 'cp', 'trestbps',
                                             'chol', 'fbs', 'restecg',
                                             'thalach', 'exang', 'oldpeak',
                                             'slope', 'ca', 'thal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=n...
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=6140,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2023-02-24 01:47:07,000:INFO:save_model() successfully completed......................................
2023-02-24 01:55:07,591:INFO:PyCaret ClassificationExperiment
2023-02-24 01:55:07,591:INFO:Logging name: clf-default-name
2023-02-24 01:55:07,591:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-02-24 01:55:07,591:INFO:version 3.0.0.rc9
2023-02-24 01:55:07,591:INFO:Initializing setup()
2023-02-24 01:55:07,591:INFO:self.USI: 6422
2023-02-24 01:55:07,591:INFO:self._variable_keys: {'y_test', '_available_plots', 'y', 'exp_name_log', 'y_train', 'log_plots_param', 'is_multiclass', 'exp_id', 'idx', 'X_test', 'seed', 'n_jobs_param', 'gpu_n_jobs_param', 'target_param', 'html_param', 'fold_groups_param', 'X_train', 'logging_param', 'data', 'fold_generator', 'USI', 'X', 'fix_imbalance', 'memory', 'fold_shuffle_param', '_ml_usecase', 'pipeline', 'gpu_param'}
2023-02-24 01:55:07,591:INFO:Checking environment
2023-02-24 01:55:07,591:INFO:python_version: 3.10.8
2023-02-24 01:55:07,592:INFO:python_build: ('main', 'Oct 13 2022 10:17:43')
2023-02-24 01:55:07,592:INFO:machine: x86_64
2023-02-24 01:55:07,592:INFO:platform: macOS-12.6.1-x86_64-i386-64bit
2023-02-24 01:55:07,592:INFO:Memory: svmem(total=8589934592, available=3158646784, percent=63.2, used=4293300224, free=487591936, active=2679783424, inactive=2644160512, wired=1613516800)
2023-02-24 01:55:07,592:INFO:Physical Core: 2
2023-02-24 01:55:07,592:INFO:Logical Core: 2
2023-02-24 01:55:07,592:INFO:Checking libraries
2023-02-24 01:55:07,592:INFO:System:
2023-02-24 01:55:07,592:INFO:    python: 3.10.8 (main, Oct 13 2022, 10:17:43) [Clang 14.0.0 (clang-1400.0.29.102)]
2023-02-24 01:55:07,592:INFO:executable: /usr/local/opt/python@3.10/bin/python3.10
2023-02-24 01:55:07,592:INFO:   machine: macOS-12.6.1-x86_64-i386-64bit
2023-02-24 01:55:07,592:INFO:PyCaret required dependencies:
2023-02-24 01:55:07,593:INFO:                 pip: 23.0.1
2023-02-24 01:55:07,593:INFO:          setuptools: 65.4.1
2023-02-24 01:55:07,593:INFO:             pycaret: 3.0.0rc9
2023-02-24 01:55:07,593:INFO:             IPython: 8.10.0
2023-02-24 01:55:07,593:INFO:          ipywidgets: 8.0.4
2023-02-24 01:55:07,593:INFO:                tqdm: 4.64.1
2023-02-24 01:55:07,593:INFO:               numpy: 1.23.5
2023-02-24 01:55:07,593:INFO:              pandas: 1.5.2
2023-02-24 01:55:07,593:INFO:              jinja2: 3.1.2
2023-02-24 01:55:07,593:INFO:               scipy: 1.9.3
2023-02-24 01:55:07,593:INFO:              joblib: 1.2.0
2023-02-24 01:55:07,594:INFO:             sklearn: 1.0.2
2023-02-24 01:55:07,594:INFO:                pyod: 1.0.7
2023-02-24 01:55:07,594:INFO:            imblearn: 0.10.1
2023-02-24 01:55:07,594:INFO:   category_encoders: 2.6.0
2023-02-24 01:55:07,595:INFO:            lightgbm: 3.3.5
2023-02-24 01:55:07,595:INFO:               numba: 0.56.4
2023-02-24 01:55:07,595:INFO:            requests: 2.28.2
2023-02-24 01:55:07,595:INFO:          matplotlib: 3.6.3
2023-02-24 01:55:07,595:INFO:          scikitplot: 0.3.7
2023-02-24 01:55:07,595:INFO:         yellowbrick: 1.5
2023-02-24 01:55:07,596:INFO:              plotly: 5.13.0
2023-02-24 01:55:07,596:INFO:             kaleido: 0.2.1
2023-02-24 01:55:07,596:INFO:         statsmodels: 0.13.5
2023-02-24 01:55:07,596:INFO:              sktime: 0.16.1
2023-02-24 01:55:07,596:INFO:               tbats: 1.1.2
2023-02-24 01:55:07,598:INFO:            pmdarima: 2.0.2
2023-02-24 01:55:07,598:INFO:              psutil: 5.9.4
2023-02-24 01:55:07,598:INFO:PyCaret optional dependencies:
2023-02-24 01:55:07,600:INFO:                shap: Not installed
2023-02-24 01:55:07,600:INFO:           interpret: Not installed
2023-02-24 01:55:07,600:INFO:                umap: Not installed
2023-02-24 01:55:07,600:INFO:    pandas_profiling: 4.0.0
2023-02-24 01:55:07,600:INFO:  explainerdashboard: Not installed
2023-02-24 01:55:07,600:INFO:             autoviz: Not installed
2023-02-24 01:55:07,600:INFO:           fairlearn: Not installed
2023-02-24 01:55:07,600:INFO:             xgboost: Not installed
2023-02-24 01:55:07,600:INFO:            catboost: Not installed
2023-02-24 01:55:07,600:INFO:              kmodes: Not installed
2023-02-24 01:55:07,600:INFO:             mlxtend: Not installed
2023-02-24 01:55:07,601:INFO:       statsforecast: Not installed
2023-02-24 01:55:07,601:INFO:        tune_sklearn: Not installed
2023-02-24 01:55:07,601:INFO:                 ray: Not installed
2023-02-24 01:55:07,601:INFO:            hyperopt: Not installed
2023-02-24 01:55:07,601:INFO:              optuna: Not installed
2023-02-24 01:55:07,601:INFO:               skopt: Not installed
2023-02-24 01:55:07,601:INFO:              mlflow: Not installed
2023-02-24 01:55:07,601:INFO:              gradio: Not installed
2023-02-24 01:55:07,601:INFO:             fastapi: Not installed
2023-02-24 01:55:07,601:INFO:             uvicorn: Not installed
2023-02-24 01:55:07,601:INFO:              m2cgen: Not installed
2023-02-24 01:55:07,601:INFO:           evidently: Not installed
2023-02-24 01:55:07,601:INFO:               fugue: Not installed
2023-02-24 01:55:07,601:INFO:           streamlit: 1.17.0
2023-02-24 01:55:07,601:INFO:             prophet: Not installed
2023-02-24 01:55:07,601:INFO:None
2023-02-24 01:55:07,601:INFO:Set up data.
2023-02-24 01:55:07,612:INFO:Set up train/test split.
2023-02-24 01:55:07,624:INFO:Set up index.
2023-02-24 01:55:07,624:INFO:Set up folding strategy.
2023-02-24 01:55:07,625:INFO:Assigning column types.
2023-02-24 01:55:07,632:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-24 01:55:07,706:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-24 01:55:07,708:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-24 01:55:07,757:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:55:07,758:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:55:07,905:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-24 01:55:07,906:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-24 01:55:08,000:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:55:08,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:55:08,001:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-24 01:55:08,074:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-24 01:55:08,122:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:55:08,123:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:55:08,202:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-24 01:55:08,273:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:55:08,273:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:55:08,274:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-02-24 01:55:08,574:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:55:08,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:55:08,691:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:55:08,691:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:55:08,692:INFO:Preparing preprocessing pipeline...
2023-02-24 01:55:08,694:INFO:Set up simple imputation.
2023-02-24 01:55:08,716:INFO:Finished creating preprocessing pipeline.
2023-02-24 01:55:08,720:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/dq/s9918lj122qb5j_dx_8x106m0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'sex', 'cp', 'trestbps',
                                             'chol', 'fbs', 'restecg',
                                             'thalach', 'exang', 'oldpeak',
                                             'slope', 'ca', 'thal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-02-24 01:55:08,720:INFO:Creating final display dataframe.
2023-02-24 01:55:08,925:INFO:Setup _display_container:                     Description             Value
0                    Session id              6216
1                        Target            target
2                   Target type            Binary
3           Original data shape         (303, 14)
4        Transformed data shape         (303, 14)
5   Transformed train set shape         (212, 14)
6    Transformed test set shape          (91, 14)
7              Numeric features                13
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              6422
2023-02-24 01:55:09,171:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:55:09,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:55:09,359:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:55:09,359:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-24 01:55:09,360:INFO:setup() successfully completed in 1.77s...............
2023-02-24 01:55:09,375:INFO:Initializing compare_models()
2023-02-24 01:55:09,376:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1307853c0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x1307853c0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-02-24 01:55:09,379:INFO:Checking exceptions
2023-02-24 01:55:09,406:INFO:Preparing display monitor
2023-02-24 01:55:09,412:INFO:Initializing Logistic Regression
2023-02-24 01:55:09,412:INFO:Total runtime is 3.3338864644368488e-06 minutes
2023-02-24 01:55:09,412:INFO:SubProcess create_model() called ==================================
2023-02-24 01:55:09,416:INFO:Initializing create_model()
2023-02-24 01:55:09,416:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1307853c0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131638ac0>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:55:09,416:INFO:Checking exceptions
2023-02-24 01:55:09,416:INFO:Importing libraries
2023-02-24 01:55:09,417:INFO:Copying training dataset
2023-02-24 01:55:09,438:INFO:Defining folds
2023-02-24 01:55:09,438:INFO:Declaring metric variables
2023-02-24 01:55:09,438:INFO:Importing untrained model
2023-02-24 01:55:09,438:INFO:Logistic Regression Imported successfully
2023-02-24 01:55:09,439:INFO:Starting cross validation
2023-02-24 01:55:09,439:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:55:24,507:INFO:Calculating mean and std
2023-02-24 01:55:24,510:INFO:Creating metrics dataframe
2023-02-24 01:55:24,525:INFO:Uploading results into container
2023-02-24 01:55:24,526:INFO:Uploading model into container now
2023-02-24 01:55:24,527:INFO:_master_model_container: 1
2023-02-24 01:55:24,527:INFO:_display_container: 2
2023-02-24 01:55:24,528:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-02-24 01:55:24,528:INFO:create_model() successfully completed......................................
2023-02-24 01:55:24,729:INFO:SubProcess create_model() end ==================================
2023-02-24 01:55:24,730:INFO:Creating metrics dataframe
2023-02-24 01:55:24,736:INFO:Initializing K Neighbors Classifier
2023-02-24 01:55:24,736:INFO:Total runtime is 0.2553999185562134 minutes
2023-02-24 01:55:24,736:INFO:SubProcess create_model() called ==================================
2023-02-24 01:55:24,736:INFO:Initializing create_model()
2023-02-24 01:55:24,737:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1307853c0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131638ac0>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:55:24,737:INFO:Checking exceptions
2023-02-24 01:55:24,737:INFO:Importing libraries
2023-02-24 01:55:24,737:INFO:Copying training dataset
2023-02-24 01:55:24,742:INFO:Defining folds
2023-02-24 01:55:24,742:INFO:Declaring metric variables
2023-02-24 01:55:24,742:INFO:Importing untrained model
2023-02-24 01:55:24,743:INFO:K Neighbors Classifier Imported successfully
2023-02-24 01:55:24,743:INFO:Starting cross validation
2023-02-24 01:55:24,745:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:55:24,898:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-24 01:55:24,931:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-24 01:55:25,050:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-24 01:55:25,058:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-24 01:55:25,146:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-24 01:55:25,176:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-24 01:55:25,223:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-24 01:55:25,258:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-24 01:55:25,329:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-24 01:55:25,347:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-24 01:55:25,387:INFO:Calculating mean and std
2023-02-24 01:55:25,388:INFO:Creating metrics dataframe
2023-02-24 01:55:25,393:INFO:Uploading results into container
2023-02-24 01:55:25,393:INFO:Uploading model into container now
2023-02-24 01:55:25,394:INFO:_master_model_container: 2
2023-02-24 01:55:25,394:INFO:_display_container: 2
2023-02-24 01:55:25,394:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-02-24 01:55:25,395:INFO:create_model() successfully completed......................................
2023-02-24 01:55:25,537:INFO:SubProcess create_model() end ==================================
2023-02-24 01:55:25,537:INFO:Creating metrics dataframe
2023-02-24 01:55:25,547:INFO:Initializing Naive Bayes
2023-02-24 01:55:25,547:INFO:Total runtime is 0.26891621748606365 minutes
2023-02-24 01:55:25,547:INFO:SubProcess create_model() called ==================================
2023-02-24 01:55:25,548:INFO:Initializing create_model()
2023-02-24 01:55:25,548:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1307853c0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131638ac0>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:55:25,548:INFO:Checking exceptions
2023-02-24 01:55:25,548:INFO:Importing libraries
2023-02-24 01:55:25,548:INFO:Copying training dataset
2023-02-24 01:55:25,556:INFO:Defining folds
2023-02-24 01:55:25,557:INFO:Declaring metric variables
2023-02-24 01:55:25,557:INFO:Importing untrained model
2023-02-24 01:55:25,557:INFO:Naive Bayes Imported successfully
2023-02-24 01:55:25,558:INFO:Starting cross validation
2023-02-24 01:55:25,559:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:55:25,986:INFO:Calculating mean and std
2023-02-24 01:55:25,987:INFO:Creating metrics dataframe
2023-02-24 01:55:25,993:INFO:Uploading results into container
2023-02-24 01:55:25,994:INFO:Uploading model into container now
2023-02-24 01:55:25,994:INFO:_master_model_container: 3
2023-02-24 01:55:25,994:INFO:_display_container: 2
2023-02-24 01:55:25,995:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-02-24 01:55:25,995:INFO:create_model() successfully completed......................................
2023-02-24 01:55:26,186:INFO:SubProcess create_model() end ==================================
2023-02-24 01:55:26,187:INFO:Creating metrics dataframe
2023-02-24 01:55:26,195:INFO:Initializing Decision Tree Classifier
2023-02-24 01:55:26,195:INFO:Total runtime is 0.27972264687220255 minutes
2023-02-24 01:55:26,195:INFO:SubProcess create_model() called ==================================
2023-02-24 01:55:26,196:INFO:Initializing create_model()
2023-02-24 01:55:26,196:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1307853c0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131638ac0>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:55:26,196:INFO:Checking exceptions
2023-02-24 01:55:26,196:INFO:Importing libraries
2023-02-24 01:55:26,196:INFO:Copying training dataset
2023-02-24 01:55:26,207:INFO:Defining folds
2023-02-24 01:55:26,208:INFO:Declaring metric variables
2023-02-24 01:55:26,209:INFO:Importing untrained model
2023-02-24 01:55:26,209:INFO:Decision Tree Classifier Imported successfully
2023-02-24 01:55:26,210:INFO:Starting cross validation
2023-02-24 01:55:26,211:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:55:27,094:INFO:Calculating mean and std
2023-02-24 01:55:27,095:INFO:Creating metrics dataframe
2023-02-24 01:55:27,106:INFO:Uploading results into container
2023-02-24 01:55:27,107:INFO:Uploading model into container now
2023-02-24 01:55:27,108:INFO:_master_model_container: 4
2023-02-24 01:55:27,108:INFO:_display_container: 2
2023-02-24 01:55:27,108:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6216, splitter='best')
2023-02-24 01:55:27,109:INFO:create_model() successfully completed......................................
2023-02-24 01:55:27,320:INFO:SubProcess create_model() end ==================================
2023-02-24 01:55:27,323:INFO:Creating metrics dataframe
2023-02-24 01:55:27,333:INFO:Initializing SVM - Linear Kernel
2023-02-24 01:55:27,335:INFO:Total runtime is 0.29871211846669515 minutes
2023-02-24 01:55:27,337:INFO:SubProcess create_model() called ==================================
2023-02-24 01:55:27,337:INFO:Initializing create_model()
2023-02-24 01:55:27,337:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1307853c0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131638ac0>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:55:27,337:INFO:Checking exceptions
2023-02-24 01:55:27,338:INFO:Importing libraries
2023-02-24 01:55:27,338:INFO:Copying training dataset
2023-02-24 01:55:27,344:INFO:Defining folds
2023-02-24 01:55:27,346:INFO:Declaring metric variables
2023-02-24 01:55:27,346:INFO:Importing untrained model
2023-02-24 01:55:27,347:INFO:SVM - Linear Kernel Imported successfully
2023-02-24 01:55:27,348:INFO:Starting cross validation
2023-02-24 01:55:27,349:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:55:27,510:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-24 01:55:27,761:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-24 01:55:27,826:WARNING:/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-24 01:55:27,831:INFO:Calculating mean and std
2023-02-24 01:55:27,836:INFO:Creating metrics dataframe
2023-02-24 01:55:27,843:INFO:Uploading results into container
2023-02-24 01:55:27,844:INFO:Uploading model into container now
2023-02-24 01:55:27,845:INFO:_master_model_container: 5
2023-02-24 01:55:27,846:INFO:_display_container: 2
2023-02-24 01:55:27,846:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6216, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-24 01:55:27,846:INFO:create_model() successfully completed......................................
2023-02-24 01:55:28,110:INFO:SubProcess create_model() end ==================================
2023-02-24 01:55:28,110:INFO:Creating metrics dataframe
2023-02-24 01:55:28,142:INFO:Initializing Ridge Classifier
2023-02-24 01:55:28,144:INFO:Total runtime is 0.31220630009969075 minutes
2023-02-24 01:55:28,155:INFO:SubProcess create_model() called ==================================
2023-02-24 01:55:28,155:INFO:Initializing create_model()
2023-02-24 01:55:28,155:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1307853c0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131638ac0>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:55:28,155:INFO:Checking exceptions
2023-02-24 01:55:28,155:INFO:Importing libraries
2023-02-24 01:55:28,155:INFO:Copying training dataset
2023-02-24 01:55:28,174:INFO:Defining folds
2023-02-24 01:55:28,174:INFO:Declaring metric variables
2023-02-24 01:55:28,175:INFO:Importing untrained model
2023-02-24 01:55:28,175:INFO:Ridge Classifier Imported successfully
2023-02-24 01:55:28,176:INFO:Starting cross validation
2023-02-24 01:55:28,180:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:55:28,680:INFO:Calculating mean and std
2023-02-24 01:55:28,687:INFO:Creating metrics dataframe
2023-02-24 01:55:28,692:INFO:Uploading results into container
2023-02-24 01:55:28,693:INFO:Uploading model into container now
2023-02-24 01:55:28,694:INFO:_master_model_container: 6
2023-02-24 01:55:28,694:INFO:_display_container: 2
2023-02-24 01:55:28,694:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=6216, solver='auto', tol=0.001)
2023-02-24 01:55:28,694:INFO:create_model() successfully completed......................................
2023-02-24 01:55:28,831:INFO:SubProcess create_model() end ==================================
2023-02-24 01:55:28,831:INFO:Creating metrics dataframe
2023-02-24 01:55:28,839:INFO:Initializing Random Forest Classifier
2023-02-24 01:55:28,839:INFO:Total runtime is 0.3237896998723348 minutes
2023-02-24 01:55:28,840:INFO:SubProcess create_model() called ==================================
2023-02-24 01:55:28,840:INFO:Initializing create_model()
2023-02-24 01:55:28,840:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1307853c0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131638ac0>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:55:28,840:INFO:Checking exceptions
2023-02-24 01:55:28,840:INFO:Importing libraries
2023-02-24 01:55:28,840:INFO:Copying training dataset
2023-02-24 01:55:28,846:INFO:Defining folds
2023-02-24 01:55:28,846:INFO:Declaring metric variables
2023-02-24 01:55:28,847:INFO:Importing untrained model
2023-02-24 01:55:28,847:INFO:Random Forest Classifier Imported successfully
2023-02-24 01:55:28,848:INFO:Starting cross validation
2023-02-24 01:55:28,850:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:55:32,680:INFO:Calculating mean and std
2023-02-24 01:55:32,681:INFO:Creating metrics dataframe
2023-02-24 01:55:32,689:INFO:Uploading results into container
2023-02-24 01:55:32,691:INFO:Uploading model into container now
2023-02-24 01:55:32,691:INFO:_master_model_container: 7
2023-02-24 01:55:32,692:INFO:_display_container: 2
2023-02-24 01:55:32,692:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6216, verbose=0, warm_start=False)
2023-02-24 01:55:32,693:INFO:create_model() successfully completed......................................
2023-02-24 01:55:32,825:INFO:SubProcess create_model() end ==================================
2023-02-24 01:55:32,825:INFO:Creating metrics dataframe
2023-02-24 01:55:32,833:INFO:Initializing Quadratic Discriminant Analysis
2023-02-24 01:55:32,833:INFO:Total runtime is 0.390357498327891 minutes
2023-02-24 01:55:32,834:INFO:SubProcess create_model() called ==================================
2023-02-24 01:55:32,834:INFO:Initializing create_model()
2023-02-24 01:55:32,834:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1307853c0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131638ac0>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:55:32,834:INFO:Checking exceptions
2023-02-24 01:55:32,834:INFO:Importing libraries
2023-02-24 01:55:32,834:INFO:Copying training dataset
2023-02-24 01:55:32,839:INFO:Defining folds
2023-02-24 01:55:32,839:INFO:Declaring metric variables
2023-02-24 01:55:32,840:INFO:Importing untrained model
2023-02-24 01:55:32,841:INFO:Quadratic Discriminant Analysis Imported successfully
2023-02-24 01:55:32,841:INFO:Starting cross validation
2023-02-24 01:55:32,843:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:55:33,265:INFO:Calculating mean and std
2023-02-24 01:55:33,266:INFO:Creating metrics dataframe
2023-02-24 01:55:33,275:INFO:Uploading results into container
2023-02-24 01:55:33,276:INFO:Uploading model into container now
2023-02-24 01:55:33,277:INFO:_master_model_container: 8
2023-02-24 01:55:33,277:INFO:_display_container: 2
2023-02-24 01:55:33,277:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-02-24 01:55:33,277:INFO:create_model() successfully completed......................................
2023-02-24 01:55:33,407:INFO:SubProcess create_model() end ==================================
2023-02-24 01:55:33,407:INFO:Creating metrics dataframe
2023-02-24 01:55:33,416:INFO:Initializing Ada Boost Classifier
2023-02-24 01:55:33,416:INFO:Total runtime is 0.4000637968381246 minutes
2023-02-24 01:55:33,416:INFO:SubProcess create_model() called ==================================
2023-02-24 01:55:33,417:INFO:Initializing create_model()
2023-02-24 01:55:33,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1307853c0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131638ac0>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:55:33,417:INFO:Checking exceptions
2023-02-24 01:55:33,417:INFO:Importing libraries
2023-02-24 01:55:33,417:INFO:Copying training dataset
2023-02-24 01:55:33,423:INFO:Defining folds
2023-02-24 01:55:33,423:INFO:Declaring metric variables
2023-02-24 01:55:33,424:INFO:Importing untrained model
2023-02-24 01:55:33,425:INFO:Ada Boost Classifier Imported successfully
2023-02-24 01:55:33,425:INFO:Starting cross validation
2023-02-24 01:55:33,430:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:55:35,204:INFO:Calculating mean and std
2023-02-24 01:55:35,205:INFO:Creating metrics dataframe
2023-02-24 01:55:35,211:INFO:Uploading results into container
2023-02-24 01:55:35,212:INFO:Uploading model into container now
2023-02-24 01:55:35,213:INFO:_master_model_container: 9
2023-02-24 01:55:35,213:INFO:_display_container: 2
2023-02-24 01:55:35,214:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=6216)
2023-02-24 01:55:35,214:INFO:create_model() successfully completed......................................
2023-02-24 01:55:35,348:INFO:SubProcess create_model() end ==================================
2023-02-24 01:55:35,348:INFO:Creating metrics dataframe
2023-02-24 01:55:35,356:INFO:Initializing Gradient Boosting Classifier
2023-02-24 01:55:35,356:INFO:Total runtime is 0.432398267587026 minutes
2023-02-24 01:55:35,356:INFO:SubProcess create_model() called ==================================
2023-02-24 01:55:35,356:INFO:Initializing create_model()
2023-02-24 01:55:35,356:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1307853c0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131638ac0>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:55:35,357:INFO:Checking exceptions
2023-02-24 01:55:35,357:INFO:Importing libraries
2023-02-24 01:55:35,357:INFO:Copying training dataset
2023-02-24 01:55:35,362:INFO:Defining folds
2023-02-24 01:55:35,362:INFO:Declaring metric variables
2023-02-24 01:55:35,364:INFO:Importing untrained model
2023-02-24 01:55:35,364:INFO:Gradient Boosting Classifier Imported successfully
2023-02-24 01:55:35,368:INFO:Starting cross validation
2023-02-24 01:55:35,370:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:55:37,347:INFO:Calculating mean and std
2023-02-24 01:55:37,348:INFO:Creating metrics dataframe
2023-02-24 01:55:37,354:INFO:Uploading results into container
2023-02-24 01:55:37,356:INFO:Uploading model into container now
2023-02-24 01:55:37,357:INFO:_master_model_container: 10
2023-02-24 01:55:37,357:INFO:_display_container: 2
2023-02-24 01:55:37,358:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6216, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-24 01:55:37,358:INFO:create_model() successfully completed......................................
2023-02-24 01:55:37,496:INFO:SubProcess create_model() end ==================================
2023-02-24 01:55:37,497:INFO:Creating metrics dataframe
2023-02-24 01:55:37,505:INFO:Initializing Linear Discriminant Analysis
2023-02-24 01:55:37,505:INFO:Total runtime is 0.4682140032450358 minutes
2023-02-24 01:55:37,505:INFO:SubProcess create_model() called ==================================
2023-02-24 01:55:37,505:INFO:Initializing create_model()
2023-02-24 01:55:37,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1307853c0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131638ac0>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:55:37,505:INFO:Checking exceptions
2023-02-24 01:55:37,506:INFO:Importing libraries
2023-02-24 01:55:37,506:INFO:Copying training dataset
2023-02-24 01:55:37,511:INFO:Defining folds
2023-02-24 01:55:37,511:INFO:Declaring metric variables
2023-02-24 01:55:37,511:INFO:Importing untrained model
2023-02-24 01:55:37,512:INFO:Linear Discriminant Analysis Imported successfully
2023-02-24 01:55:37,513:INFO:Starting cross validation
2023-02-24 01:55:37,514:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:55:37,945:INFO:Calculating mean and std
2023-02-24 01:55:37,946:INFO:Creating metrics dataframe
2023-02-24 01:55:37,953:INFO:Uploading results into container
2023-02-24 01:55:37,954:INFO:Uploading model into container now
2023-02-24 01:55:37,955:INFO:_master_model_container: 11
2023-02-24 01:55:37,955:INFO:_display_container: 2
2023-02-24 01:55:37,955:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-02-24 01:55:37,955:INFO:create_model() successfully completed......................................
2023-02-24 01:55:38,085:INFO:SubProcess create_model() end ==================================
2023-02-24 01:55:38,085:INFO:Creating metrics dataframe
2023-02-24 01:55:38,093:INFO:Initializing Extra Trees Classifier
2023-02-24 01:55:38,094:INFO:Total runtime is 0.4780335346857707 minutes
2023-02-24 01:55:38,094:INFO:SubProcess create_model() called ==================================
2023-02-24 01:55:38,095:INFO:Initializing create_model()
2023-02-24 01:55:38,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1307853c0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131638ac0>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:55:38,095:INFO:Checking exceptions
2023-02-24 01:55:38,095:INFO:Importing libraries
2023-02-24 01:55:38,095:INFO:Copying training dataset
2023-02-24 01:55:38,100:INFO:Defining folds
2023-02-24 01:55:38,100:INFO:Declaring metric variables
2023-02-24 01:55:38,101:INFO:Importing untrained model
2023-02-24 01:55:38,102:INFO:Extra Trees Classifier Imported successfully
2023-02-24 01:55:38,102:INFO:Starting cross validation
2023-02-24 01:55:38,103:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:55:41,611:INFO:Calculating mean and std
2023-02-24 01:55:41,612:INFO:Creating metrics dataframe
2023-02-24 01:55:41,620:INFO:Uploading results into container
2023-02-24 01:55:41,622:INFO:Uploading model into container now
2023-02-24 01:55:41,623:INFO:_master_model_container: 12
2023-02-24 01:55:41,623:INFO:_display_container: 2
2023-02-24 01:55:41,624:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6216, verbose=0, warm_start=False)
2023-02-24 01:55:41,624:INFO:create_model() successfully completed......................................
2023-02-24 01:55:41,785:INFO:SubProcess create_model() end ==================================
2023-02-24 01:55:41,785:INFO:Creating metrics dataframe
2023-02-24 01:55:41,793:INFO:Initializing Light Gradient Boosting Machine
2023-02-24 01:55:41,793:INFO:Total runtime is 0.5396857182184855 minutes
2023-02-24 01:55:41,793:INFO:SubProcess create_model() called ==================================
2023-02-24 01:55:41,794:INFO:Initializing create_model()
2023-02-24 01:55:41,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1307853c0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131638ac0>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:55:41,794:INFO:Checking exceptions
2023-02-24 01:55:41,794:INFO:Importing libraries
2023-02-24 01:55:41,794:INFO:Copying training dataset
2023-02-24 01:55:41,801:INFO:Defining folds
2023-02-24 01:55:41,802:INFO:Declaring metric variables
2023-02-24 01:55:41,802:INFO:Importing untrained model
2023-02-24 01:55:41,803:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-24 01:55:41,803:INFO:Starting cross validation
2023-02-24 01:55:41,804:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:55:42,715:INFO:Calculating mean and std
2023-02-24 01:55:42,716:INFO:Creating metrics dataframe
2023-02-24 01:55:42,721:INFO:Uploading results into container
2023-02-24 01:55:42,722:INFO:Uploading model into container now
2023-02-24 01:55:42,723:INFO:_master_model_container: 13
2023-02-24 01:55:42,723:INFO:_display_container: 2
2023-02-24 01:55:42,724:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6216, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-24 01:55:42,724:INFO:create_model() successfully completed......................................
2023-02-24 01:55:42,865:INFO:SubProcess create_model() end ==================================
2023-02-24 01:55:42,866:INFO:Creating metrics dataframe
2023-02-24 01:55:42,877:INFO:Initializing Dummy Classifier
2023-02-24 01:55:42,878:INFO:Total runtime is 0.557761033376058 minutes
2023-02-24 01:55:42,878:INFO:SubProcess create_model() called ==================================
2023-02-24 01:55:42,878:INFO:Initializing create_model()
2023-02-24 01:55:42,878:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1307853c0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x131638ac0>, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:55:42,878:INFO:Checking exceptions
2023-02-24 01:55:42,878:INFO:Importing libraries
2023-02-24 01:55:42,878:INFO:Copying training dataset
2023-02-24 01:55:42,891:INFO:Defining folds
2023-02-24 01:55:42,892:INFO:Declaring metric variables
2023-02-24 01:55:42,892:INFO:Importing untrained model
2023-02-24 01:55:42,893:INFO:Dummy Classifier Imported successfully
2023-02-24 01:55:42,893:INFO:Starting cross validation
2023-02-24 01:55:42,894:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-24 01:55:43,345:INFO:Calculating mean and std
2023-02-24 01:55:43,346:INFO:Creating metrics dataframe
2023-02-24 01:55:43,352:INFO:Uploading results into container
2023-02-24 01:55:43,353:INFO:Uploading model into container now
2023-02-24 01:55:43,354:INFO:_master_model_container: 14
2023-02-24 01:55:43,355:INFO:_display_container: 2
2023-02-24 01:55:43,355:INFO:DummyClassifier(constant=None, random_state=6216, strategy='prior')
2023-02-24 01:55:43,355:INFO:create_model() successfully completed......................................
2023-02-24 01:55:43,485:INFO:SubProcess create_model() end ==================================
2023-02-24 01:55:43,485:INFO:Creating metrics dataframe
2023-02-24 01:55:43,500:INFO:Initializing create_model()
2023-02-24 01:55:43,500:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1307853c0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6216, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-24 01:55:43,500:INFO:Checking exceptions
2023-02-24 01:55:43,502:INFO:Importing libraries
2023-02-24 01:55:43,502:INFO:Copying training dataset
2023-02-24 01:55:43,507:INFO:Defining folds
2023-02-24 01:55:43,507:INFO:Declaring metric variables
2023-02-24 01:55:43,508:INFO:Importing untrained model
2023-02-24 01:55:43,508:INFO:Declaring custom model
2023-02-24 01:55:43,509:INFO:Random Forest Classifier Imported successfully
2023-02-24 01:55:43,509:INFO:Cross validation set to False
2023-02-24 01:55:43,510:INFO:Fitting Model
2023-02-24 01:55:43,898:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6216, verbose=0, warm_start=False)
2023-02-24 01:55:43,899:INFO:create_model() successfully completed......................................
2023-02-24 01:55:44,060:INFO:_master_model_container: 14
2023-02-24 01:55:44,060:INFO:_display_container: 2
2023-02-24 01:55:44,061:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6216, verbose=0, warm_start=False)
2023-02-24 01:55:44,061:INFO:compare_models() successfully completed......................................
2023-02-24 01:55:44,069:INFO:Initializing save_model()
2023-02-24 01:55:44,070:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6216, verbose=0, warm_start=False), model_name=best_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/dq/s9918lj122qb5j_dx_8x106m0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'sex', 'cp', 'trestbps',
                                             'chol', 'fbs', 'restecg',
                                             'thalach', 'exang', 'oldpeak',
                                             'slope', 'ca', 'thal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-02-24 01:55:44,070:INFO:Adding model into prep_pipe
2023-02-24 01:55:44,184:INFO:best_model.pkl saved in current working directory
2023-02-24 01:55:44,203:INFO:Pipeline(memory=FastMemory(location=/var/folders/dq/s9918lj122qb5j_dx_8x106m0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'sex', 'cp', 'trestbps',
                                             'chol', 'fbs', 'restecg',
                                             'thalach', 'exang', 'oldpeak',
                                             'slope', 'ca', 'thal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=n...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='auto',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=6216,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-02-24 01:55:44,203:INFO:save_model() successfully completed......................................
2023-02-24 01:56:28,445:WARNING:/usr/local/lib/python3.10/site-packages/multimethod/__init__.py:315: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`
  return func(*args, **kwargs)

